# CHAPTER 4

# 아이스버그 테이블의 성능 최적화

아이스버그 테이블은 3장에서 보았듯이 쿼리 엔진이 더 스마트한 쿼리 계획을 세울 수 있도록 메타데이터 레이어를 제공합니다. 하지만 이 메타데이터는 데이터 성능을 최적화할 수 있는 방법의 시작에 불과합니다.

데이터파일 수 감소, 데이터 정렬, 테이블 파티셔닝, 행 수준 업데이트 처리, 메트릭 수집, 외부 요소 등 다양한 최적화 레버를 활용할 수 있습니다. 이러한 레버들은 데이터 성능 향상에 중요한 역할을 하며, 이 장에서는 각각에 대해 살펴보고 잠재적인 성능 저하 문제를 해결하고 가속화 통찰력을 제공합니다. 최적화 필요성을 식별하기 위해 선호하는 도구로 강력한 모니터링을 구현하는 것이 중요하며, 여기에는 10장에서 다룰 아파치 아이스버그 메타데이터 테이블 사용도 포함됩니다.

## 압축(Compaction)

모든 절차나 프로세스는 시간 측면에서 비용이 발생하며, 이는 쿼리 시간이 길어지고 컴퓨팅 비용이 높아진다는 의미입니다. 다르게 말하면, 작업을 수행하는 데 필요한 단계가 많을수록 작업 시간이 길어집니다. 아파치 아이스버그 테이블을 쿼리할 때는 각 파일을 열고 스캔한 다음 완료되면 파일을 닫아야 합니다. 쿼리에 스캔해야 할 파일이 많을수록 이러한 파일 작업이 쿼리에 더 큰 비용을 부과합니다. 이 문제는 데이터가 생성될 때 수집되는 스트리밍 또는 "실시간" 데이터 세계에서 더욱 확대되며, 각 파일에 몇 개의 레코드만 포함된 많은 파일이 생성됩니다.

반면에 배치 수집은 하루 또는 일주일 분량의 레코드를 한 작업으로 수집할 수 있어 더 효율적으로 데이터를 계획하고 더 잘 구성된 파일로 작성할 수 있습니다. 배치 수집에서도 "작은 파일 문제"가 발생할 수 있습니다. 너무 많은 작은 파일이 있으면 더 많은 파일 작업을 수행하고, 더 많은 메타데이터를 읽고(각 파일에 대한 메타데이터가 있음), 정리 및 유지 관리 작업 시 더 많은 파일을 삭제해야 하기 때문에 스캔 속도와 성능에 영향을 미칩니다. 그림 4-1은 이 두 시나리오를 보여줍니다.

본질적으로 데이터를 읽을 때는 피할 수 없는 고정 비용과 다양한 전략을 사용하여 피할 수 있는 가변 비용이 있습니다. 고정 비용에는 쿼리와 관련된 특정 데이터를 읽는 것이 포함됩니다. 데이터를 처리하려면 데이터를 읽어야 하므로 이를 피할 수 없습니다. 반면 가변 비용에는 데이터에 접근하기 위한 파일 작업이 포함되며, 이 장에서 논의할 많은 전략을 사용하여 이러한 가변 비용을 최대한 줄일 수 있습니다. 이러한 전략을 사용하면 작업을 더 저렴하고 더 빠르게 수행하는 데 필요한 컴퓨팅만 사용하게 됩니다(작업을 더 빠르게 완료할 수 있다는 이점은 컴퓨팅 클러스터를 더 빨리 종료할 수 있어 비용을 절감할 수 있습니다).

이 문제에 대한 해결책은 주기적으로 이러한 모든 작은 파일의 데이터를 가져와 더 적은 수의 큰 파일로 다시 작성하는 것입니다(데이터파일 수에 비해 매니페스트 파일이 너무 많은 경우 매니페스트도 다시 작성할 수 있습니다). 이 프로세스를 압축(compaction)이라고 하며, 많은 파일을 몇 개로 압축하기 때문입니다. 압축은 그림 4-2에 나와 있습니다.

## 압축 실습

이 솔루션이 간단해 보이지만 Java나 Python으로 광범위한 코드를 작성해야 한다고 생각할 수 있습니다. 다행히도 아파치 아이스버그의 Actions 패키지에는 여러 유지 관리 절차가 포함되어 있습니다(Actions 패키지는 특별히 아파치 스파크용이지만 다른 엔진도 자체 유지 관리 작업 구현을 만들 수 있습니다). 이 패키지는 이 장의 대부분에서 보여주는 것처럼 SparkSQL을 작성하거나 다음과 같은 명령형 코드를 작성하여 스파크 내에서 사용됩니다(이러한 작업은 여전히 일반 아이스버그 트랜잭션과 동일한 ACID 보장을 유지함을 명심하세요):

```java
Table table = catalog.loadTable("myTable");
SparkActions
 .get()
 .rewriteDataFiles(table)
 .option("rewrite-job-order", "files-desc")
 .execute();
```

이 스니펫에서는 테이블의 새 인스턴스를 초기화한 다음 rewriteDataFiles를 트리거했습니다. 이는 압축을 위한 스파크 액션입니다. SparkActions에서 사용하는 빌더 패턴을 통해 여러 메소드를 함께 연결하여 압축 작업을 미세 조정할 수 있으며, 압축을 수행할지 여부뿐만 아니라 어떻게 수행할지도 표현할 수 있습니다.

rewriteDataFiles 호출과 작업을 시작하는 execute 메소드 사이에 체인할 수 있는 몇 가지 메소드가 있습니다:

**binPack**  
압축 전략을 binpack으로 설정합니다(나중에 설명됨). 이는 기본값이므로 명시적으로 제공할 필요가 없습니다

**Sort**  
압축 전략을 우선순위 순서로 하나 이상의 필드로 정렬된 데이터로 변경합니다. "압축 전략" 섹션에서 자세히 설명합니다

**zOrder**  
압축 전략을 동일한 가중치로 여러 필드를 기반으로 z-order 정렬하도록 변경합니다. "정렬" 섹션에서 자세히 설명합니다

**filter**  
다시 작성할 파일을 제한하는 데 사용되는 표현식을 전달할 수 있습니다

**option**  
단일 옵션을 변경합니다

**options**  
여러 옵션 구성의 맵을 사용합니다

작업을 구성하기 위해 전달할 수 있는 몇 가지 가능한 옵션이 있습니다. 중요한 몇 가지는 다음과 같습니다:

**target-file-size-bytes**  
출력 파일의 의도된 크기를 설정합니다. 기본적으로 이는 테이블의 write.target.file-size-bytes 속성을 사용하며, 기본값은 512MB입니다.

**max-concurrent-file-group-rewrites**  
동시에 쓸 파일 그룹 수의 상한입니다.

**max-file-group-size-bytes**  
파일 그룹의 최대 크기는 단일 파일이 아닙니다. 이 설정은 특정 파일 그룹을 작성하는 워커에 사용 가능한 메모리보다 큰 파티션을 처리할 때 사용해야 하며, 그 파티션을 여러 파일 그룹으로 분할하여 동시에 작성할 수 있습니다.

**partial-progress-enabled**  
파일 그룹이 압축되는 동안 커밋이 발생할 수 있도록 합니다. 따라서 장기 실행 압축의 경우 동시 쿼리가 이미 압축된 파일의 혜택을 받을 수 있습니다.

**partial-progress-max-commits**  
부분 진행이 활성화된 경우 이 설정은 작업을 완료하는 데 허용되는 최대 커밋 수를 설정합니다.

**rewrite-job-order**  
파일 그룹을 작성하는 순서로, 부분 진행을 사용할 때 우선순위가 높은 파일 그룹이 나중보다는 빨리 커밋되도록 하는 데 중요할 수 있습니다. 바이트 크기 또는 그룹의 파일 수를 기준으로 순서를 지정할 수 있습니다(bytes-asc, bytes-desc, files-asc, files-desc, none).

## 파일 크기와 행 그룹 크기

아파치 파켓 파일의 경우 행 그룹 크기와 파일 크기가 있습니다. 행 그룹 크기는 파켓 파일에서 한 그룹의 행 크기이며, 각 파일은 여러 그룹을 가질 수 있습니다. 따라서 아이스버그 테이블의 기본 구성은 128MB 행 그룹 크기와 512MB 파일 크기(파일당 4개의 행 그룹)를 허용합니다. 이 두 설정이 항상 정렬되도록 해야 합니다(즉, 행 크기가 파일 크기로 균등하게 나누어지도록). 행 그룹이 적을수록 파일 크기가 작아지는데, 이는 그룹 메타데이터를 작성할 그룹이 적기 때문입니다. 반면 행 그룹이 많을수록 조건 푸시다운이 개선됩니다. 행 그룹 메타데이터는 더 세분화된 범위를 가질 수 있어 쿼리 엔진이 현재 쿼리와 관련 없는 데이터가 포함된 더 많은 행 그룹을 제거할 수 있기 때문입니다.

또 다른 예로, 파일 크기를 파일당 1GB로 늘리되 행 그룹은 128MB(파일당 8개의 행 그룹)로 유지하고 싶을 수 있습니다. 이렇게 하면 열고 닫을 파일이 줄어듭니다. 실행 중인 쿼리 유형이 종종 대부분의 데이터를 읽어야 하는 경우 조건 푸시다운이 모든 데이터를 가져오는 프로세스를 빠르게 하지 않으므로 행 그룹이 적은 것이 좋습니다.

행 그룹 크기와 파일 크기는 모두 테이블 속성(write.parquet.row-group-size-bytes 및 write.target-file-size-bytes)으로 설정할 수 있지만, 파일 크기는 옵션 설정을 사용하여 개별 압축 작업에 대해 설정할 수 있습니다.

엔진이 압축 작업에서 작성할 새 파일을 계획할 때 병렬로 작성될 파일 그룹(즉, 각 그룹에서 하나의 파일을 동시에 작성할 수 있음)으로 이러한 파일을 그룹화하기 시작합니다. 압축 작업에서 이러한 파일 그룹의 크기와 동시에 작성해야 하는 파일 그룹 수를 구성하는 옵션을 구성하여 메모리 문제를 방지할 수 있습니다.

## 부분 진행

부분 진행을 통해 파일 그룹이 완료되면 새 스냅샷을 생성할 수 있습니다. 이를 통해 쿼리는 다른 파일이 완료되는 동안 이미 압축된 파일의 혜택을 받을 수 있습니다. 또한 작업이 완료되면 진행 상황이 저장되고 메모리에 보관해야 하는 데이터가 줄어들기 때문에 대규모 압축 작업의 메모리 부족(OOM) 상황을 방지하는 데 도움이 됩니다.

더 많은 스냅샷은 테이블 위치에 저장 공간을 차지하는 더 많은 메타데이터 파일을 의미한다는 점을 명심하세요. 그러나 독자가 압축 작업의 혜택을 더 빨리 받기를 원한다면 이는 유용한 기능일 수 있습니다. 추가 스냅샷의 비용과 부분 진행의 이점 사이의 균형을 맞추고 싶다면 단일 압축 작업이 수행할 총 커밋 수를 제한하도록 max-commits를 조정할 수 있습니다.

다음 코드 스니펫은 가능한 테이블 옵션 중 여러 개를 실제로 사용합니다:

```java
Table table = catalog.loadTable("myTable");
SparkActions
 .get()
 .rewriteDataFiles(table)
 .sort()
 .filter(Expressions.and(
 Expressions.greaterThanOrEqual("date", "2023-01-01"),
 Expressions.lessThanOrEqual("date", "2023-01-31")))
 .option("rewrite-job-order", "files-desc")
 .execute();
```

위 예제에서는 기본적으로 테이블 속성에 지정된 정렬 순서를 준수하는 정렬 전략을 구현했습니다. 또한 1월 데이터만 다시 작성하는 필터를 포함했습니다. 이 필터는 아파치 아이스버그의 내부 표현식 구축 인터페이스를 사용하여 표현식을 생성해야 한다는 점에 유의해야 합니다. 또한 rewrite-job-order를 더 큰 파일 그룹을 먼저 다시 작성하도록 구성했습니다. 이는 5개 파일 그룹에서 다시 작성되는 파일이 2개 파일만 통합하는 파일보다 먼저 처리된다는 의미입니다.

Expressions 라이브러리는 아파치 아이스버그의 메타데이터 구조 주변에 표현식을 생성하도록 설계되었습니다. 이 라이브러리는 이러한 표현식을 구축하고 조작하기 위한 API를 제공하며, 이는 테이블 및 읽기 작업에서 데이터를 필터링하는 데 사용할 수 있습니다. 아이스버그의 표현식은 또한 매니페스트 파일에서 각 데이터파일의 데이터를 요약하는 데 사용할 수 있으며, 이를 통해 아이스버그는 필터와 일치할 수 있는 행이 없는 파일을 건너뛸 수 있습니다. 이 메커니즘은 아이스버그의 확장 가능한 메타데이터 아키텍처에 필수적입니다.

이 모든 것이 좋고 좋지만, 스파크 SQL 확장 기능을 사용하면 더 쉽게 수행할 수 있습니다. 이 확장에는 다음 구문을 사용하여 스파크 SQL에서 호출할 수 있는 호출 프로시저가 포함되어 있습니다:

```sql
-- 위치 인수 사용
CALL catalog.system.procedure(arg1, arg2, arg3)
-- 명명된 인수 사용
CALL catalog.system.procedure(argkey1 => argval1, argkey2 => argval2)
```

이 구문에서 rewriteDataFiles 프로시저를 사용하면 예제 4-1과 같이 보입니다.

예제 4-1. rewrite_data_files 프로시저를 사용하여 압축 작업 실행

```sql
-- SparkSQL에서 rewrite_data_files CALL 프로시저
CALL catalog.system.rewrite_data_files(
 table => 'musicians',
 strategy => 'binpack',
 where => 'genre = "rock"',
 options => map(
 'rewrite-job-order','bytes-asc',
 'target-file-size-bytes','1073741824', -- 1GB
 'max-file-group-size-bytes','10737418240' -- 10GB
 )
)
```

이 시나리오에서는 musicians 테이블에 일부 데이터를 스트리밍하고 록 밴드에 대해 많은 작은 파일이 생성된 것을 발견했으므로, 시간이 많이 걸릴 수 있는 전체 테이블에서 압축을 실행하는 대신 문제가 있는 데이터만 대상으로 지정했습니다. 또한 스파크에게 바이트 단위로 더 큰 파일 그룹에 우선순위를 두고 각 파일을 약 1GB, 각 파일 그룹을 약 10GB로 유지하도록 지시했습니다. 그림 4-3에서 이러한 설정의 결과를 볼 수 있습니다.

예제 4-1에서 where 필터에 큰따옴표를 사용한 것에 주목하세요. 필터 주위에 작은따옴표를 사용해야 했기 때문에 SQL에서 일반적으로 "rock"에 작은따옴표를 사용하더라도 문자열에 큰따옴표를 사용합니다. where 옵션은 본질적으로 앞서 언급한 filter 메소드와 동일합니다. 이 옵션이 없으면 전체 테이블이 다시 작성될 수 있습니다.

다른 엔진도 자체 사용자 지정 압축 도구를 구현할 수 있습니다. 예를 들어, Dremio는 OPTIMIZE 명령을 통해 자체 아이스버그 테이블 관리 기능을 가지고 있으며, 이는 고유한 구현이지만 RewriteDataFiles 액션의 많은 API를 따릅니다:

```sql
OPTIMIZE TABLE catalog.MyTable
```

위 명령은 모든 파일을 더 적고 최적화된 파일로 압축하는 기본 binpack 압축을 수행합니다. 그러나 스파크의 rewriteDataFiles 프로시저처럼 더 세분화된 작업도 가능합니다.

예를 들어, 여기서는 특정 파티션만 압축합니다:

```sql
OPTIMIZE TABLE catalog.MyTable
 FOR PARTITIONS sales_year IN (2022, 2023) AND sales_month IN ('JAN', 'FEB',
'MAR')
```

그리고 여기서는 특정 파일 크기 매개변수로 압축합니다:

```sql
OPTIMIZE TABLE catalog.MyTable 
 REWRITE DATA (MIN_FILE_SIZE_MB=100, MAX_FILE_SIZE_MB=1000, 
TARGET_FILE_SIZE_MB=512)
```

이 코드 스니펫에서는 매니페스트만 다시 작성합니다:

```sql
OPTIMIZE TABLE catalog.MyTable 
 REWRITE MANIFESTS
```

보시다시피 스파크나 Dremio를 사용하여 아파치 아이스버그 테이블의 압축을 수행할 수 있습니다.

## 압축 전략

앞서 언급했듯이 rewriteDataFiles 프로시저를 사용할 때 여러 압축 전략을 사용할 수 있습니다. 표 4-1은 장단점을 포함한 이러한 전략을 요약합니다. 이 섹션에서는 binpack 압축에 대해 논의할 것이며, 표준 정렬 및 z-order 정렬은 책의 뒷부분에서 다룰 것입니다.

표 4-1. 압축 전략의 장단점

|전략|수행 작업|장점|단점|
|---|---|---|---|
|Binpack|파일만 결합하며 전역 정렬은 없음(작업 내에서 로컬 정렬 수행)|가장 빠른 압축 작업 제공|데이터가 클러스터링되지 않음|
|Sort|작업 할당 전에 하나 이상의 필드를 순차적으로 정렬(예: 필드 a로 정렬 후 그 안에서 필드 b로 정렬)|자주 쿼리되는 필드로 클러스터링된 데이터는 읽기 시간을 크게 단축|binpack에 비해 압축 작업 시간이 더 김|
|z-order|작업 할당 전에 동일한 가중치를 갖는 여러 필드로 정렬(이 범위의 X 및 Y 값은 한 그룹에 있고, 다른 범위의 값들은 다른 그룹에 있음)|쿼리가 종종 여러 필드에 대한 필터에 의존하는 경우 읽기 시간을 더욱 향상|binpack에 비해 압축 작업 실행 시간이 더 김|

binpack 전략은 본질적으로 파일 크기 이외의 데이터 구성 방식에 대한 다른 고려 사항 없이 순수한 압축입니다. 세 가지 전략 중 binpack이 가장 빠른데, 더 작은 파일의 내용을 대상 크기의 더 큰 파일에 쓸 수 있기 때문입니다. 반면 sort와 z-order는 파일 그룹을 작성 할당하기 전에 데이터를 정렬해야 합니다. 이는 SLA(서비스 수준 계약)를 충족하는 속도로 압축을 실행해야 하는 스트리밍 데이터가 있을 때 특히 유용합니다.

아파치 아이스버그 테이블이 설정 내에서 정렬 순서를 설정한 경우, binpack을 사용하더라도 이 정렬 순서는 단일 작업 내에서 데이터를 정렬하는 데 사용됩니다(로컬 정렬). sort 및 z-order 전략을 사용하면 쿼리 엔진이 레코드를 다른 작업에 할당하기 전에 데이터를 정렬하여 작업 간 데이터 클러스터링을 최적화합니다.

스트리밍 데이터를 수집하는 경우 매 시간 후에 수집된 데이터에 대해 빠른 압축을 실행해야 할 수 있습니다. 다음과 같은 작업을 수행할 수 있습니다:

```sql
CALL catalog.system.rewrite_data_files(
 table => 'streamingtable',
 strategy => 'binpack',
 where => 'created_at between "2023-01-26 09:00:00" and "2023-01-26 09:59:59" ',
 options => map(
 'rewrite-job-order','bytes-asc',
 'target-file-size-bytes','1073741824',
 'max-file-group-size-bytes','10737418240',
 'partial-progress-enabled', 'true'
 )
)
```

이 압축 작업에서는 스트리밍 SLA 요구 사항에 맞게 더 빠른 alignment를 위해 binpack 전략을 사용합니다. 이는 특히 가장 최근 한 시간으로 동적으로 조정할 수 있는 한 시간 시간 프레임 내의 데이터 수집을 대상으로 합니다. 부분 진행 커밋을 사용하면 파일 그룹이 작성될 때 즉시 커밋되어 독자에게 즉각적인 성능 향상을 가져옵니다. 중요한 것은 이 압축 프로세스가 이전에 작성된 데이터에만 초점을 맞추고 새로운 데이터파일을 도입할 스트리밍 작업에서 오는 동시 쓰기와 격리시킨다는 점입니다.

제한된 범위의 데이터에 더 빠른 전략을 사용하면 압축 작업이 훨씬 빨라질 수 있습니다. 물론 한 시간 이상의 압축을 허용하면 데이터를 더 압축할 수 있지만, 압축 작업을 빠르게 실행해야 하는 필요성과 최적화 필요성 사이의 균형을 맞춰야 합니다. 하루 분량의 데이터에 대한 추가 압축 작업을 야간에, 그리고 일주일 분량의 데이터에 대한 압축 작업을 주말에 실행하여 다른 작업에 최대한 적게 간섭하면서 지속적인 간격으로 최적화를 유지할 수 있습니다. 압축은 항상 현재 파티션 스펙을 준수하므로 이전 파티션 스펙의 데이터가 다시 작성되면 새로운 파티셔닝 규칙이 적용됩니다.

## 압축 자동화

이러한 압축 작업을 수동으로 실행하면 모든 SLA를 충족하기 어려울 수 있으므로, 이러한 프로세스 자동화 방법을 살펴보는 것이 큰 이점이 될 수 있습니다. 이러한 작업을 자동화하는 몇 가지 접근 방식은 다음과 같습니다:

- Airflow, Dagster, Prefect, Argo 또는 Luigi와 같은 오케스트레이션 도구를 사용하여 수집 작업이 완료된 후 또는 특정 시간이나 주기적 간격으로 적절한 SQL을 스파크나 Dremio와 같은 엔진에 보낼 수 있습니다.
- 데이터가 클라우드 객체 스토리지에 저장된 후 작업을 트리거하는 서버리스 함수를 사용할 수 있습니다.
- 특정 시간에 적절한 작업을 실행하도록 cron 작업을 설정할 수 있습니다.

이러한 접근 방식은 수동으로 스크립트를 작성하고 이러한 서비스를 배포해야 합니다. 그러나 자동화된 테이블 유지 관리 및 압축 기능을 갖춘 관리형 아파치 아이스버그 카탈로그 서비스 클래스도 있습니다. 이러한 서비스의 예로는 Dremio Arctic 및 Tabular가 있습니다.

## 정렬

정렬 압축 전략의 세부 사항을 살펴보기 전에, 테이블 최적화와 관련된 정렬에 대해 이해해 보겠습니다.

데이터 정렬 또는 "클러스터링"은 쿼리에 있어 매우 특별한 이점이 있습니다. 쿼리에 필요한 데이터를 얻기 위해 스캔해야 하는 파일 수를 제한하는 데 도움이 됩니다. 데이터를 정렬하면 유사한 값을 가진 데이터가 더 적은 수의 파일에 집중되어 더 효율적인 쿼리 계획을 세울 수 있습니다.

예를 들어, 특별한 방식으로 정렬되지 않은 100개의 파켓 파일에 걸쳐 모든 NFL 팀의 모든 선수를 나타내는 데이터셋이 있다고 가정해 보겠습니다. 디트로이트 라이온스 팀 선수만 쿼리하는 경우, 100개의 레코드가 있는 파일에 디트로이트 라이온스 선수 레코드가 하나만 있더라도 해당 파일은 쿼리 계획에 추가되어 스캔되어야 합니다. 이는 최대 53개의 파일(NFL 팀에 있을 수 있는 최대 선수 수)을 스캔해야 할 수 있음을 의미합니다. 데이터를 팀 이름별로 알파벳순으로 정렬하면, 모든 디트로이트 라이온스 선수는 약 4개의 파일(100개 파일을 32개의 NFL 팀으로 나누면 3.125)에 있어야 하며, 이 파일에는 그린 베이 패커스와 덴버 브롱코스의 일부 선수도 포함될 수 있습니다. 따라서 데이터를 정렬함으로써 스캔해야 하는 파일 수를 가능한 53개에서 4개로 줄였으며, "압축 전략" 섹션에서 논의한 바와 같이 쿼리 성능을 크게 향상시킵니다. 그림 4-4는 정렬된 데이터셋을 스캔할 때의 이점을 보여줍니다.

정렬된 데이터는 이 예에서와 같이 특정 팀에 기반하여 NFL 데이터를 정기적으로 쿼리하는 경우와 같이 데이터가 정렬되는 방식이 일반적인 쿼리 패턴에 맞는 경우에 매우 유용할 수 있습니다. 아파치 아이스버그에서 데이터 정렬은 여러 다른 지점에서 발생할 수 있으므로 이러한 모든 지점을 활용해야 합니다.

테이블을 생성하는 두 가지 주요 방법이 있습니다. 하나는 표준 CREATE TABLE 문을 사용하는 것입니다:

```sql
-- Spark 구문
CREATE TABLE catalog.nfl_players (
 id bigint ,
 player_name varchar,
 team varchar,
 num_of_touchdowns int,
 num_of_yards int,
 player_position varchar,
 player_number int,
)
-- Dremio 구문
CREATE TABLE catalog.nfl_players (
 id bigint ,
 player_name varchar,
 team varchar,
 num_of_touchdowns int,
 num_of_yards int,
 player_position varchar,
 player_number int,
)
```

다른 하나는 CREATE TABLE…AS SELECT(CTAS) 문을 사용하는 것입니다:

```sql
-- Spark SQL & Dremio 구문
CREATE TABLE catalog.nfl_players
 AS (SELECT * FROM non_iceberg_teams_table);
```

테이블을 생성한 후, 테이블의 정렬 순서를 설정합니다. 이 속성을 지원하는 모든 엔진은 이를 사용하여 데이터를 쓰기 전에 정렬하며, 정렬 압축 전략을 사용할 때 기본 정렬 필드가 됩니다:

```sql
ALTER TABLE catalog.nfl_teams WRITE ORDERED BY team;
```

CTAS를 수행하는 경우 AS 쿼리에서 데이터를 정렬합니다:

```sql
CREATE TABLE catalog.nfl_teams
 AS (SELECT * FROM non_iceberg_teams_table ORDER BY team);
 
ALTER TABLE catalog.nfl_teams WRITE ORDERED BY team;
```

ALTER TABLE 문은 정렬 순서를 존중하는 엔진에 의한 모든 향후 쓰기에 사용될 전역 정렬 순서를 설정합니다. INSERT INTO를 사용하여 다음과 같이 지정할 수도 있습니다:

```sql
INSERT INTO catalog.nfl_teams
 SELECT *
 FROM staging_table
 ORDER BY team
```

이렇게 하면 데이터가 작성될 때 정렬되지만 완벽하지는 않습니다. 이전 예로 돌아가서, NFL 데이터셋이 팀 로스터의 변경 사항에 대해 매년 업데이트되는 경우, 여러 번 쓰기로 인해 라이온스와 패커스 선수들이 여러 파일에 분할될 수 있습니다. 이는 현재 연도의 새로운 라이온스 선수들을 위한 새 파일을 작성해야 하기 때문입니다. 이때 정렬 압축 전략이 중요해집니다.

정렬 압축 전략은 작업에서 대상으로 하는 모든 파일에 걸쳐 데이터를 정렬합니다. 예를 들어, 모든 선수를 팀별로 전역적으로 정렬하여 전체 데이터셋을 다시 작성하려면 다음 명령을 실행할 수 있습니다:

```sql
CALL catalog.system.rewrite_data_files(
 table => 'nfl_teams',
 strategy => 'sort',
 sort_order => 'team ASC NULLS LAST'
)
```

정렬 순서에 전달된 문자열의 내용은 다음과 같습니다:

**team**  
team 필드로 데이터를 정렬합니다

**ASC**  
데이터를 오름차순으로 정렬합니다(DESC는 내림차순으로 정렬)

**NULLS LAST**  
null 값이 있는 모든 선수를 워싱턴 커맨더스 다음인 정렬 끝에 배치합니다(NULLS FIRST는 애리조나 카디널스 앞에 모든 선수를 배치)

그림 4-5는 정렬 결과를 보여줍니다.

추가 필드로도 정렬할 수 있습니다. 예를 들어, 팀별로 데이터를 정렬한 다음 각 팀 내에서 이름별로 알파벳순으로 정렬하고 싶을 수 있습니다. 다음 매개변수로 작업을 실행하면 이를 달성할 수 있습니다:

```sql
CALL catalog.system.rewrite_data_files(
 table => 'nfl_teams',
 strategy => 'sort',
 sort_order => 'team ASC NULLS LAST, name ASC NULLS FIRST'
)
```

팀별 정렬이 가장 높은 가중치를 갖고, 그 다음으로 이름별 정렬이 이루어집니다. 라이온스 로스터가 끝나고 패커스 로스터가 시작되는 파일에서 그림 4-6과 같이 선수들이 이 순서로 표시될 것입니다.

최종 사용자가 정기적으로 "이름이 A로 시작하는 모든 라이온스 선수는 누구인가?"와 같은 질문을 한다면, 이러한 이중 정렬은 쿼리를 더욱 가속화할 것입니다. 그러나 최종 사용자가 "이름이 A로 시작하는 모든 NFL 선수는 누구인가?"라고 물으면, 이름만으로 정렬했을 때보다 "A" 선수들이 더 많은 파일에 분산되어 있어 도움이 되지 않을 것입니다. 이는 z-order가 유용한 경우입니다.

정렬의 최고 이점을 얻으려면 최종 사용자가 묻는 질문 유형을 이해하여 질문에 효과적으로 맞도록 데이터를 정렬해야 합니다.

## Z-order

테이블을 쿼리할 때 여러 필드가 우선순위인 경우가 있으며, 이때 z-order 정렬이 매우 유용할 수 있습니다. z-order 정렬을 사용하면 여러 데이터 포인트로 데이터를 정렬하여 엔진이 최종 쿼리 계획에서 스캔된 파일 수를 줄일 수 있는 더 큰 능력을 갖게 됩니다. 4 × 4 그리드에서 항목 Z를 찾으려고 한다고 상상해 보겠습니다(그림 4-7).

그림 4-7을 참조하면, "A"에서 우리는 값(z)을 가지고 있는데, 이 값이 3.5라고 말할 수 있으며, 데이터 내에서 검색하고자 하는 영역을 좁히고 싶습니다. 그림의 "B"와 같이 X와 Y 값의 범위에 기반하여 필드를 4개의 사분면으로 나누어 검색 범위를 좁힐 수 있습니다.

따라서 z-order로 정렬한 필드를 기반으로 찾고자 하는 데이터를 알면, 데이터가 두 필드 모두로 정렬되어 있기 때문에 데이터의 큰 부분을 검색하지 않을 수 있습니다. 그런 다음 해당 사분면을 가져와 그림의 "C"와 같이 더 세분화하고 사분면의 데이터에 다른 z-order 정렬을 적용할 수 있습니다. 우리의 검색은 여러 요소(X 및 Y)를 기반으로 하기 때문에 이 접근 방식을 통해 검색 가능한 영역의 75%를 제거할 수 있습니다.

데이터파일에서 데이터를 유사한 방식으로 정렬하고 클러스터링할 수 있습니다. 예를 들어, 의학 코호트 연구에 참여한 모든 사람의 데이터셋이 있고 코호트의 결과를 나이와 키별로 구성하려고 한다면, 데이터를 z-order로 정렬하는 것이 매우 유용할 수 있습니다. 그림 4-8에서 이를 실행 중인 것을 볼 수 있습니다.

특정 사분면에 속하는 데이터는 동일한 데이터파일에 있게 되며, 이는 다양한 나이/키 그룹에 대한 분석을 실행하려고 할 때 스캔할 파일을 크게 줄일 수 있습니다. 키가 6피트이고 나이가 60세인 사람을 검색하는 경우, 다른 세 사분면에 속하는 데이터가 있는 데이터파일을 즉시 제거할 수 있습니다.

이는 데이터파일이 다음 네 가지 범주로 나뉘기 때문에 작동합니다:

- A: 나이 1-50 및 키 1-5인 레코드가 포함된 파일
- B: 나이 51-100 및 키 1-5인 레코드가 포함된 파일
- C: 나이 1-50 및 키 5-10인 레코드가 포함된 파일
- D: 나이 51-100 및 키 5-10인 레코드가 포함된 파일

엔진이 나이가 60세이고 키가 6피트인 사람을 찾고 있다는 것을 알면, 쿼리를 계획할 때 아파치 아이스버그 메타데이터를 사용하여 A, B, C 범주의 모든 데이터파일이 제거되고 절대 스캔되지 않습니다. 나이로만 검색하더라도 최소한 네 개의 사분면 중 두 개를 제거할 수 있어 클러스터링의 이점을 볼 수 있습니다.

이를 달성하기 위해 압축 작업을 실행합니다:

```sql
CALL catalog.system.rewrite_data_files(
 table => 'people',
 strategy => 'sort',
 sort_order => 'zorder(age,height)'
)
```

sort 및 z-order 압축 전략을 사용하면 데이터가 존재하는 파일 수를 줄일 수 있을 뿐만 아니라, 해당 파일의 데이터 순서가 더 효율적인 쿼리 계획을 가능하게 합니다.

정렬은 효과적이지만 몇 가지 과제가 있습니다. 첫째, 새 데이터가 수집되면 정렬이 풀리고, 다음 압축 작업까지 데이터는 여러 파일에 분산된 상태로 유지됩니다. 이는 새 데이터가 새 파일에 추가되고 해당 파일 내에서 정렬될 수 있지만 이전 모든 레코드의 맥락에서는 정렬되지 않기 때문입니다. 둘째, 파일에는 여전히 정렬된 필드의 여러 값에 대한 데이터가 포함될 수 있어 특정 값만 필요한 쿼리에는 비효율적일 수 있습니다. 예를 들어, 앞서 예시에서 파일에는 라이온스와 패커스 선수 모두의 데이터가 포함되어 있어, 라이온스 선수에만 관심이 있을 때 패커스 레코드를 스캔하는 것은 비효율적입니다.

이를 해결하기 위해 파티셔닝이 있습니다.

## 파티셔닝

특정 필드가 데이터 접근 방식에 중요하다는 것을 알고 있다면, 정렬을 넘어 파티셔닝으로 나아갈 수 있습니다. 테이블이 파티셔닝되면 필드를 기반으로 정렬 순서를 정하는 대신, 대상 필드의 고유 값을 가진 레코드를 자체 데이터파일에 작성합니다.

예를 들어, 정치에서는 유권자의 당 소속에 따라 유권자 데이터를 쿼리할 가능성이 높으므로 이것은 좋은 파티션 필드입니다. 이는 "블루" 당의 모든 유권자가 "레드", "옐로우", "그린" 당과는 다른 파일에 나열됨을 의미합니다. "옐로우" 당의 유권자를 쿼리하면, 스캔하는 데이터파일 중 어느 것도 다른 당의 사람을 포함하지 않습니다. 이는 그림 4-9에 설명되어 있습니다.

전통적으로, 특정 필드의 파생된 값을 기반으로 테이블을 파티셔닝하려면 별도로 유지 관리해야 하는 추가 필드를 생성하고 쿼리할 때 사용자가 그 별도의 필드에 대한 지식을 갖고 있어야 했습니다. 예를 들어:

- 타임스탬프 열에서 일, 월, 년으로 파티셔닝하려면 년, 월, 일을 격리하여 표현하는 타임스탬프를 기반으로 추가 열을 생성해야 했습니다.
- 텍스트 값의 첫 글자로 파티셔닝하려면 그 글자만 있는 추가 열을 생성해야 했습니다.
- 버킷으로 파티셔닝(해시 함수를 기반으로 레코드를 균등하게 분배하기 위한 설정된 수의 구획)하려면 레코드가 속한 버킷을 명시하는 추가 열을 생성해야 했습니다.

그런 다음 테이블 생성 시 파티셔닝을 파생 필드를 기반으로 설정하고, 파일은 파티션에 따라 하위 디렉토리로 구성될 것입니다:

```sql
--Spark SQL
CREATE TABLE MyHiveTable (...) PARTITIONED BY month;
```

레코드를 삽입할 때마다 값을 수동으로 변환해야 했습니다:

```sql
INSERT INTO MyTable (SELECT MONTH(time) AS month, ... FROM data_source);
```

테이블을 쿼리할 때, 엔진은 원래 필드와 파생 필드 간의 관계를 인식하지 못했습니다. 이는 다음 쿼리가 파티셔닝의 혜택을 받는다는 것을 의미했습니다:

```sql
SELECT * FROM MYTABLE WHERE time BETWEEN '2022-07-01 00:00:00' AND '2022-07-31 00:00:00' AND month = 7;
```

그러나 사용자는 종종 이 우회 열을 알지 못합니다(알 필요도 없습니다). 이는 대부분의 경우 사용자가 다음과 같은 쿼리를 발행한다는 것을 의미합니다:

```sql
SELECT * FROM MYTABLE WHERE time BETWEEN '2022-07-01 00:00:00' AND '2022-07-31 00:00:00';
```

위 쿼리는 비즈니스 사용자나 데이터 분석가에게 더 직관적이며, 그들은 테이블의 내부 엔지니어링을 잘 알지 못할 수 있어 많은 우발적인 전체 테이블 스캔이 발생하게 됩니다. 이는 아이스버그의 숨겨진 파티셔닝 기능이 등장하는 지점입니다.

## 숨겨진 파티셔닝

아파치 아이스버그는 파티셔닝을 완전히 다르게 처리하여 테이블 최적화 시 이러한 많은 문제점을 해결합니다. 이 접근 방식의 결과 기능 중 하나를 숨겨진 파티셔닝이라고 합니다.

아파치 아이스버그가 파티셔닝을 추적하는 방식부터 시작합니다. 파일이 물리적으로 배치된 방식에 의존하는 대신, 아이스버그는 스냅샷 및 매니페스트 레벨에서 파티션 값 범위를 추적하여 새로운 유연성을 제공합니다:

- 변환된 값을 기반으로 파티셔닝하기 위해 추가 열을 생성할 필요 없이, 쿼리를 계획할 때 엔진과 도구가 메타데이터에서 적용할 수 있는 내장 변환을 사용할 수 있습니다.
- 이러한 변환을 사용할 때 추가 열이 필요하지 않으므로 데이터파일에 저장하는 데이터가 줄어듭니다.
- 메타데이터를 통해 엔진이 원래 열의 변환을 인식할 수 있으므로, 원래 열만 필터링하고도 파티셔닝의 이점을 얻을 수 있습니다.

즉, 월별로 파티셔닝된 테이블을 생성하면:

```sql
CREATE TABLE catalog.MyTable (...) PARTITIONED BY months(time) USING iceberg;
```

다음 쿼리는 파티셔닝의 이점을 얻습니다:

```sql
SELECT * FROM MYTABLE WHERE time BETWEEN '2022-07-01 00:00:00' AND '2022-07-31 00:00:00';
```

앞서 본 CREATE TABLE 문에서, 변환을 함수처럼 변환되는 대상 열에 적용합니다. 파티셔닝을 계획할 때 사용할 수 있는 여러 변환이 있습니다:

- year (연도만)
- month (월과 연도)
- day (일, 월, 연도)
- hour (시간, 일, 월, 연도)
- truncate
- bucket

year, month, day, hour 변환은 타임스탬프 열에서 작동합니다. month를 지정하면 메타데이터에서 추적되는 파티션 값은 타임스탬프의 월과 연도를 반영하고, day를 사용하면 연도, 월, 일을 반영한다는 점을 명심하세요. 따라서 더 세분화된 파티셔닝을 위해 여러 변환을 사용할 필요가 없습니다.

truncate 변환은 열의 잘린 값을 기반으로 테이블을 파티셔닝합니다. 예를 들어, 사람 이름의 첫 글자를 기준으로 테이블을 파티셔닝하려면 다음과 같이 테이블을 생성할 수 있습니다:

```sql
CREATE TABLE catalog.MyTable (...) PARTITIONED BY truncate(name, 1) USING iceberg;
```

bucket 변환은 높은 카디널리티(많은 고유 값)를 가진 필드를 기반으로 파티셔닝하는 데 완벽합니다. bucket 변환은 해시 함수를 사용하여 레코드를 지정된 수의 버킷으로 분배합니다. 예를 들어, 우편번호를 기반으로 유권자 데이터를 파티셔닝하고 싶지만 가능한 우편번호가 너무 많아 작은 데이터파일이 있는 너무 많은 파티션이 생길 수 있습니다. 다음과 같이 실행할 수 있습니다:

```sql
CREATE TABLE catalog.voters (...) PARTITIONED BY bucket(24, zip) USING iceberg;
```

어떤 버킷에는 여러 우편번호가 포함되지만, 적어도 특정 우편번호를 찾는 경우 전체 테이블 스캔이 아닌 해당 우편번호가 포함된 버킷만 스캔하면 됩니다. 따라서 아파치 아이스버그의 숨겨진 파티셔닝을 통해 일반적인 파티셔닝 패턴을 표현하는 더 표현력 있는 방법을 갖게 됩니다. 이를 활용하기 위해 최종 사용자는 자연스럽게 필터링할 필드만 생각하면 됩니다.

## 파티션 진화

전통적인 파티셔닝의 또 다른 도전 과제는 파일이 하위 디렉토리에 물리적으로 배치되는 구조에 의존했기 때문에, 테이블의 파티셔닝 방식을 변경하려면 전체 테이블을 다시 작성해야 했다는 것입니다. 이는 데이터와 쿼리 패턴이 발전함에 따라 데이터 파티셔닝 및 정렬 방식을 재고해야 할 때 필연적인 문제가 됩니다.

아파치 아이스버그는 메타데이터 추적 파티셔닝으로 이 문제도 해결합니다. 메타데이터는 파티션 값뿐만 아니라 과거 파티션 구성표도 추적하여 파티션 구성표가 발전할 수 있게 합니다. 따라서 두 개의 다른 파일이 두 개의 다른 파티션 구성표를 기반으로 작성된 경우, 아이스버그 메타데이터는 엔진이 인식하도록 하여 파티션 구성표 A로 계획을 별도로 만들고 파티션 구성표 B로도 별도로 만든 다음 최종적으로 전체 스캔 계획을 생성할 수 있습니다.

예를 들어, 회원이 등록한 연도별로 파티셔닝된 회원 기록 테이블이 있다고 가정해 보겠습니다:

```sql
CREATE TABLE catalog.members (...) PARTITIONED BY years(registration_ts) USING iceberg;
```

그런 다음, 몇 년 후 회원 증가 속도로 인해 레코드를 월별로 나누는 것이 가치가 있게 되었습니다. 다음과 같이 테이블을 변경하여 파티셔닝을 조정할 수 있습니다:

```sql
ALTER TABLE catalog.members ADD PARTITION FIELD months(registration_ts)
```

아파치 아이스버그의 날짜 관련 파티션 변환의 좋은 점은 더 세분화된 것으로 발전하면 덜 세분화된 파티셔닝 규칙을 제거할 필요가 없다는 것입니다. 그러나 bucket이나 truncate를 사용하고 있고 더 이상 특정 필드로 테이블을 파티셔닝하지 않기로 결정한 경우 다음과 같이 파티션 구성표를 업데이트할 수 있습니다:

```sql
ALTER TABLE catalog.members DROP PARTITION FIELD bucket(24, id);
```

파티셔닝 구성표가 업데이트되면 앞으로 테이블에 작성되는 새 데이터에만 적용되므로 기존 데이터를 다시 작성할 필요가 없습니다. 또한 rewriteDataFiles 프로시저로 다시 작성된 데이터는 새 파티셔닝 구성표를 사용하여 다시 작성되므로, 이전 데이터를 이전 구성표로 유지하려면 압축 작업에서 적절한 필터를 사용하여 다시 작성하지 않도록 해야 합니다.

## 기타 파티셔닝 고려사항

migrate 프로시저(13장에서 설명)를 사용하여 Hive 테이블을 마이그레이션한다고 가정해 보겠습니다. 현재 파생 열(예: 같은 테이블의 타임스탬프 열을 기반으로 한 월 열)로 파티셔닝되어 있을 수 있지만, 아파치 아이스버그에게 대신 아이스버그 변환을 사용해야 한다고 표현하고 싶습니다. 이러한 목적을 위한 REPLACE PARTITION 명령이 있습니다:

```sql
ALTER TABLE catalog.members REPLACE PARTITION FIELD registration_day WITH days(registration_ts) AS day_of_registration;
```

이는 데이터파일을 변경하지 않지만, 메타데이터가 아이스버그 변환을 사용하여 파티션 값을 추적할 수 있게 합니다.

테이블을 최적화하는 방법은 많습니다. 예를 들어, 파티셔닝을 사용하여 고유한 값을 가진 데이터를 고유한 파일에 쓰고, 해당 파일의 데이터를 정렬한 다음, 해당 파일을 더 적은 수의 큰 파일로 압축하면 테이블 성능이 깔끔하게 유지됩니다. 일반적인 사용 최적화만이 아니라, 행 수준 업데이트 및 삭제와 같은 특정 사용 사례도 있으며, 이는 copy-on-write 및 merge-on-read를 사용하여 최적화할 수 있습니다.

## Copy-on-Write 대 Merge-on-Read

워크로드 속도와 관련하여 또 다른 고려사항은 행 수준 업데이트를 처리하는 방법입니다. 새 데이터를 추가할 때는 새 데이터파일에 추가되지만, 업데이트하거나 삭제하기 위해 기존 행을 업데이트하려면 알아야 할 몇 가지 고려사항이 있습니다:

- 데이터 레이크, 따라서 아파치 아이스버그에서 데이터파일은 불변하며, 이는 변경할 수 없음을 의미합니다. 이는 스냅샷 격리(이전 스냅샷이 참조하는 파일이 일관된 데이터를 가짐)를 달성하는 능력과 같은 많은 이점을 제공합니다.
- 10개의 행을 업데이트하는 경우, 그들이 같은 파일에 있다는 보장이 없으므로 새 스냅샷을 위해 10개의 행을 업데이트하기 위해 10개의 파일과 그 안의 모든 데이터 행을 다시 작성해야 할 수 있습니다.

행 수준 업데이트를 처리하는 세 가지 접근 방식이 있으며, 이 섹션 전체에 걸쳐 자세히 설명되고 표 4-2에 요약되어 있습니다.

표 4-2. 아파치 아이스버그의 행 수준 업데이트 모드

|업데이트 스타일|읽기 속도|쓰기 속도|모범 사례|
|---|---|---|---|
|Copy-on-write|가장 빠른 읽기|가장 느린 업데이트/삭제||
|Merge-on-read (위치 삭제)|빠른 읽기|빠른 업데이트/삭제|읽기 비용을 최소화하기 위해 정기적인 압축 사용|
|Merge-on-read (동등성 삭제)|느린 읽기|가장 빠른 업데이트/삭제|읽기 비용을 최소화하기 위해 더 자주 압축 사용|

## Copy-on-Write

기본 접근 방식은 copy-on-write(COW)라고 합니다. 이 접근 방식에서는 데이터파일의 단일 행이라도 업데이트되거나 삭제되면, 해당 데이터파일이 다시 작성되고 새 파일이 새 스냅샷에서 기존 파일을 대체합니다. 이는 그림 4-10에 설명되어 있습니다.

이는 읽기 쿼리가 삭제되거나 업데이트된 파일을 조정할 필요 없이 데이터를 읽을 수 있기 때문에 읽기 최적화에 이상적입니다. 그러나 워크로드가 매우 정기적인 행 수준 업데이트로 구성된 경우, 이러한 업데이트를 위해 전체 데이터파일을 다시 작성하면 SLA가 허용하는 것보다 업데이트가 느려질 수 있습니다. 이 접근 방식의 장점은 더 빠른 읽기이고, 단점은 느린 행 수준 업데이트 및 삭제입니다.

## Merge-on-Read

copy-on-write의 대안은 merge-on-read(MOR)로, 전체 데이터파일을 다시 작성하는 대신 삭제 파일에 기존 파일에서 업데이트할 레코드를 캡처합니다. 이 삭제 파일은 무시해야 할 레코드를 추적합니다.

레코드를 삭제하는 경우:

- 레코드가 삭제 파일에 나열됩니다.
- 리더가 테이블을 읽을 때 데이터파일과 삭제 파일을 조정합니다.

레코드를 업데이트하는 경우:

- 업데이트할 레코드가 삭제 파일에 추적됩니다.
- 업데이트된 레코드만 포함하는 새 데이터파일이 생성됩니다.
- 리더가 테이블을 읽을 때 삭제 파일 때문에 레코드의 이전 버전을 무시하고 새 데이터파일의 새 버전을 사용합니다.

이는 그림 4-11에 설명되어 있습니다.

이는 업데이트할 레코드가 있는 데이터파일에 변경되지 않은 레코드를 새 파일로 다시 작성할 필요성을 피함으로써 쓰기 트랜잭션 속도를 높입니다. 그러나 쿼리가 적절한 데이터파일에서 무시할 레코드를 알기 위해 삭제 파일을 스캔해야 하므로 읽기가 느려지는 비용이 발생합니다.

읽기 비용을 최소화하기 위해 정기적인 압축 작업을 실행하고, 그러한 압축 작업이 효율적으로 실행되도록 하기 위해 이전에 배운 일부 속성을 활용하고 싶을 것입니다:

- 마지막 시간 프레임(시간, 일)에 수집된 파일에만 압축을 실행하기 위해 필터/where 절을 사용합니다.
- 파일 그룹이 다시 작성될 때 커밋을 만들어 독자가 점진적 개선을 더 빨리 보기 시작할 수 있도록 부분 진행 모드를 사용합니다.

이러한 기술을 사용하면 읽기 성능에 대한 비용을 최소화하면서 많은 업데이트 워크로드의 쓰기 측면을 가속화할 수 있습니다. 이 접근 방식의 장점은 더 빠른 행 수준 업데이트이지만, 삭제 파일을 조정해야 하기 때문에 더 느린 읽기라는 단점이 있습니다.

MOR 쓰기를 할 때, 삭제 파일은 미래 읽기를 위해 기존 데이터파일에서 무시해야 할 레코드를 추적할 수 있게 합니다. 다른 유형의 삭제 파일 간의 상위 수준 개념을 이해하는 데 도움이 되는 비유를 사용하겠습니다. (어떤 유형의 삭제 파일이 작성되는지는 일반적으로 특정 사용 사례에 대한 테이블 설정이 아니라 엔진에 의해 결정된다는 점을 명심하세요.)

많은 데이터가 있고 특정 행을 제거하려면 몇 가지 옵션이 있습니다:

- 데이터셋에서의 위치를 기반으로 행 데이터를 찾을 수 있습니다. 마치 영화관에서 좌석 번호로 친구를 찾는 것과 같습니다.
- 그것이 무엇으로 이루어져 있는지를 기반으로 행 데이터를 찾을 수 있습니다. 마치 밝은 빨간 모자를 쓰고 있기 때문에 군중 속에서 친구를 찾는 것과 같습니다.

첫 번째 옵션을 사용하면 위치 삭제 파일을 사용하게 됩니다. 두 번째 옵션을 사용하면 동등성 삭제 파일이 필요합니다. 각 방법은 자체적인 강점과 약점이 있습니다. 이는 상황에 따라 하나를 다른 것보다 선호할 수 있다는 것을 의미합니다. 가장 적합한 것을 선택하는 것이 중요합니다!

이 두 유형의 삭제 파일을 살펴보겠습니다. 위치 삭제는 어떤 파일의 어떤 행을 무시해야 하는지 추적합니다. 다음 표는 위치 삭제 파일에 이 데이터가 어떻게 배치되는지 예시입니다:

삭제할 행(위치 삭제)

|파일 경로|위치|
|---|---|
|001.parquet|0|
|001.parquet|5|
|006.parquet|5|

지정된 파일을 읽을 때, 위치 삭제 파일은 지정된 위치의 행을 건너뜁니다. 이는 특정 지점에서 행을 건너뛰어야 하므로 읽기 시간에 훨씬 작은 비용이 발생합니다. 그러나 이는 쓰기 시간 비용이 있습니다. 삭제 파일 작성자는 삭제된 레코드의 위치를 알아야 하며, 이는 해당 위치를 식별하기 위해 삭제된 레코드가 있는 파일을 읽어야 한다는 것을 의미합니다.

동등성 삭제는 대신 레코드가 일치하면 무시해야 하는 값을 지정합니다. 다음 표는 동등성 삭제 파일의 데이터가 어떻게 배치될 수 있는지 보여줍니다:

삭제할 행(동등성 삭제)

|팀|주|
|---|---|
|Yellow|NY|
|Green|MA|

이는 대상 값을 추적하기 위해 파일을 열고 읽을 필요가 없으므로 쓰기 시간 비용이 없지만, 훨씬 더 큰 읽기 시간 비용이 있습니다. 읽기 시간 비용은 일치하는 값을 가진 레코드가 어디에 존재하는지에 대한 정보가 없기 때문에 발생합니다. 따라서 데이터를 읽을 때 일치하는 레코드를 포함할 수 있는 모든 레코드와 비교해야 합니다. 동등성 삭제는 가능한 가장 빠른 쓰기 속도가 필요한 경우에 좋지만, 읽기에 미치는 영향을 줄이기 위해 적극적인 압축을 계획해야 합니다.

## COW 및 MOR 구성

테이블이 COW 또는 MOR을 통해 행 수준 업데이트를 처리하도록 구성되는지 여부는 다음에 따라 달라집니다:

- 테이블 속성
- 아파치 아이스버그에 쓰는 데 사용하는 엔진이 MOR 쓰기를 지원하는지 여부

다음 테이블 속성은 특정 트랜잭션이 COW 또는 MOR을 통해 처리되는지 여부를 결정합니다:

**write.delete.mode**  
삭제 트랜잭션에 사용할 접근 방식

**write.update.mode**  
업데이트 트랜잭션에 사용할 접근 방식

**write.merge.mode**  
병합 트랜잭션에 사용할 접근 방식

이 속성과 모든 아파치 아이스버그 테이블 속성에 대해, 많은 것이 명세의 일부이지만 여전히 특정 컴퓨팅 엔진이 명세를 따르는 것에 달려 있다는 점을 명심하세요. 이러한 속성을 사용하는 특정 작업에 사용하는 엔진에서 어떤 테이블 속성이 존중되는지 읽어봐야 할 수 있습니다. 쿼리 엔진 개발자는 모든 아파치 아이스버그 테이블 속성을 존중할 의도가 있지만, 이는 특정 엔진의 아키텍처에 맞는 구현이 필요합니다. 시간이 지남에 따라 엔진은 모든 속성을 존중해야 하므로 모든 엔진에서 동일한 동작을 얻을 수 있어야 합니다.

아파치 스파크에 대한 아파치 아이스버그 지원은 아파치 아이스버그 프로젝트 내에서 처리되므로, 이러한 모든 속성은 스파크 내에서 존중되며 다음과 같이 스파크에서 테이블을 생성할 때 설정할 수 있습니다:

```sql
CREATE TABLE catalog.people (
 id int,
 first_name string,
 last_name string
) TBLPROPERTIES (
 'write.delete.mode'='copy-on-write',
 'write.update.mode'='merge-on-read',
 'write.merge.mode'='merge-on-read'
) USING iceberg;
```

이 속성은 테이블이 생성된 후 ALTER TABLE 문을 사용하여 설정할 수도 있습니다:

```sql
ALTER TABLE catalog.people SET TBLPROPERTIES (
 'write.delete.mode'='merge-on-read',
 'write.update.mode'='copy-on-write',
 'write.merge.mode'='copy-on-write'
);
```

그것으로 충분합니다. 그러나 비-아파치 스파크 엔진과 작업할 때 다음을 기억하세요:

- 테이블 속성이 존중될 수도 있고 아닐 수도 있습니다. 엔진이 지원을 구현하는 것은 엔진의 몫입니다.
- MOR을 사용할 때, 데이터를 쿼리하는 데 사용하는 엔진이 삭제 파일을 읽을 수 있는지 확인하세요.

## 기타 고려사항

데이터파일과 그 구성 방식 외에도 성능을 향상시키기 위한 많은 레버가 있습니다. 다음 섹션에서 그 중 많은 것을 논의할 것입니다.

## 메트릭 수집

2장에서 논의한 바와 같이, 각 데이터파일 그룹의 매니페스트는 min/max 필터링 및 기타 최적화에 도움이 되는 테이블의 각 필드에 대한 메트릭을 추적합니다. 추적되는 열 수준 메트릭의 유형에는 다음이 포함됩니다:

- 값, null 값 및 고유 값 수
- 상한 및 하한 값

매우 넓은 테이블(즉, 많은 필드가 있는 테이블, 예: 100개 이상)이 있는 경우, 추적되는 메트릭 수가 메타데이터 읽기에 부담이 되기 시작할 수 있습니다. 다행히도 아파치 아이스버그의 테이블 속성을 사용하여 어떤 열의 메트릭을 추적하고 어떤 열은 추적하지 않을지 미세 조정할 수 있습니다. 이렇게 하면 쿼리 필터에 자주 사용되는 열에 대한 메트릭을 추적하고 그렇지 않은 열에 대한 메트릭은 캡처하지 않아 메타데이터를 부풀리지 않을 수 있습니다.

테이블 속성을 사용하여 원하는 열의 메트릭 수집 수준을 다음과 같이 조정할 수 있습니다(모든 열을 지정할 필요는 없음):

```sql
ALTER TABLE catalog.db.students SET TBLPROPERTIES (
 'write.metadata.metrics.column.col1'='none',
 'write.metadata.metrics.column.col2'='full',
 'write.metadata.metrics.column.col3'='counts',
 'write.metadata.metrics.column.col4'='truncate(16)',
);
```

보시다시피, 각 개별 열에 대해 메트릭을 수집하는 방법을 여러 가능한 값으로 설정할 수 있습니다:

**none**  
메트릭을 수집하지 않습니다.

**counts**  
카운트만 수집합니다(값, 고유 값, null 값).

**truncate(XX)**  
값을 특정 문자 수로 잘라내어 카운트하고, 상한/하한을 그 기반으로 합니다. 예를 들어, 문자열 열은 16자로 잘릴 수 있으며 메타데이터 값 범위는 축약된 문자열 값을 기반으로 합니다.

**full**  
전체 값을 기반으로 카운트와 상한/하한을 계산합니다.

모든 열에 대해 이를 명시적으로 설정할 필요는 없습니다. 기본적으로 아이스버그는 이를 truncate(16)으로 설정합니다.

## 매니페스트 다시 작성

때로는 문제가 데이터파일이 아닙니다. 데이터파일은 잘 크기가 조정되고 잘 정렬되어 있습니다. 문제는 여러 스냅샷에 걸쳐 작성되어 개별 매니페스트가 더 많은 데이터파일을 나열할 수 있다는 것입니다. 매니페스트가 더 가벼워도, 더 많은 매니페스트는 여전히 더 많은 파일 작업을 의미합니다. 매니페스트 파일만 다시 작성하여 총 매니페스트 파일 수를 줄이고 해당 매니페스트 파일이 많은 수의 데이터파일을 나열하도록 하는 별도의 rewriteManifests 프로시저가 있습니다:

```sql
CALL catalog.system.rewrite_manifests('MyTable')
```

이 작업을 실행하는 동안 메모리 문제가 발생하면 두 번째 인수로 false를 전달하여 스파크 캐싱을 끌 수 있습니다. 많은 매니페스트를 다시 작성하고 스파크에 의해 캐싱되고 있다면 개별 실행기 노드에 문제가 발생할 수 있습니다:

```sql
CALL catalog.system.rewrite_manifests('MyTable', false)
```

이 작업을 실행하는 것이 좋은 경우는 데이터파일 크기가 최적이지만 매니페스트 파일 수가 그렇지 않은 경우입니다. 예를 들어, 한 파티션에 5GB의 데이터가 10개의 데이터파일로 분할되어 있지만 이러한 파일이 5개의 매니페스트 파일 내에 나열되어 있다면, 데이터파일을 다시 작성할 필요는 없지만 10개의 파일을 하나의 매니페스트로 통합할 수 있습니다.

## 스토리지 최적화

테이블을 업데이트하거나 압축 작업을 실행할 때 새 파일이 생성되지만, 이전 파일은 테이블의 과거 스냅샷과 연결되어 있기 때문에 삭제되지 않습니다. 불필요한 많은 데이터를 저장하는 것을 방지하기 위해 정기적으로 스냅샷을 만료시켜야 합니다. 만료된 스냅샷으로는 시간 여행을 할 수 없다는 점을 명심하세요. 만료 중에 여전히 유효한 스냅샷과 연결되지 않은 데이터파일은 삭제됩니다.

특정 타임스탬프 이전에 생성된 스냅샷을 만료시킬 수 있습니다:

```sql
CALL catalog.system.expire_snapshots('MyTable', TIMESTAMP '2023-02-01 00:00:00.000', 100)
```

두 번째 인수는 유지할 최소 스냅샷 수입니다(기본적으로 마지막 5일의 스냅샷을 유지함). 따라서 타임스탬프 이전의 스냅샷만 만료됩니다. 그러나 스냅샷이 가장 최근 100개 스냅샷 내에 있으면 만료되지 않습니다.

특정 스냅샷 ID도 만료시킬 수 있습니다:

```sql
CALL catalog.system.expire_snapshots(table => 'MyTable', snapshot_ids => ARRAY(53))
```

이 예에서는 ID가 53인 스냅샷이 만료됩니다. metadata.json 파일을 열고 내용을 검사하거나 10장에서 자세히 설명할 메타데이터 테이블을 사용하여 스냅샷 ID를 찾을 수 있습니다. 민감한 데이터를 실수로 노출한 스냅샷이 있을 수 있고 해당 트랜잭션에서 생성된 데이터파일을 정리하기 위해 해당 단일 스냅샷을 만료시키고 싶을 수 있습니다. 이를 통해 그러한 유연성을 얻을 수 있습니다. 만료는 트랜잭션이므로 유효한 스냅샷 목록이 업데이트된 새 metadata.json 파일이 생성됩니다.

expire_snapshots 프로시저에 전달할 수 있는 여섯 가지 인수가 있습니다:

**table**  
작업을 실행할 테이블

**older_than**  
이 타임스탬프 이전의 모든 스냅샷을 만료시킵니다

**retain_last**  
유지할 최소 스냅샷 수

**snapshot_ids**  
만료시킬 특정 스냅샷 ID

**max_concurrent_deletes**  
파일 삭제에 사용할 스레드 수

**stream_results**  
true일 때, 삭제된 파일을 RDD 파티션별로 스파크 드라이버에 보냅니다. 대용량 파일을 삭제할 때 OOM 문제를 방지하는 데 유용합니다

스토리지를 최적화할 때 또 다른 고려 사항은 고아 파일입니다. 이는 실패한 작업에 의해 작성되었기 때문에 메타데이터 트리에서 추적되지 않지만 테이블의 데이터 디렉토리에 축적되는 파일과 아티팩트입니다. 이러한 파일은 스냅샷을 만료시켜도 정리되지 않으므로, 이를 처리하기 위한 특별한 프로시저를 주기적으로 실행해야 합니다.

이 프로시저는 테이블의 기본 위치에 있는 모든 파일을 살펴보고 활성 스냅샷과 관련이 있는지 평가합니다. 이는 집약적인 프로세스일 수 있습니다(그래서 주기적으로만 수행해야 함). 고아 파일을 삭제하려면 다음과 같은 명령을 실행합니다:

```sql
CALL catalog.system.remove_orphan_files(table => 'MyTable')
```

removeOrphanFiles 프로시저에 다음 인수를 전달할 수 있습니다:

**table**  
작업할 테이블

**older_than**  
이 타임스탬프 이전에 생성된 파일만 삭제합니다

**location**  
고아 파일을 찾을 위치; 기본값은 테이블의 기본 위치

**dry_run**  
Boolean이 true인 경우; 파일을 삭제하지 않지만 삭제될 항목 목록을 반환합니다

**max_concurrent_deletes**  
파일 삭제에 사용할 최대 스레드 수

대부분의 테이블의 경우 데이터는 기본 위치에 있지만, addFiles 프로시저(13장에서 다룸)를 통해 외부 파일을 추가하고 나중에 이러한 디렉토리의 아티팩트를 정리하고 싶을 수 있는 경우가 있습니다. 이때 location 인수가 사용됩니다.

## 쓰기 분배 모드

쓰기 분배 모드는 MPP(대규모 병렬 처리) 시스템이 파일 쓰기를 처리하는 방법에 대한 이해가 필요합니다. 이러한 시스템은 작업이나 태스크를 수행하는 여러 노드에 작업을 분산합니다. 쓰기 분배는 쓰일 레코드가 이러한 태스크에 어떻게 분산되는지입니다. 특정 쓰기 분배 모드가 설정되지 않은 경우, 데이터는 임의로 분산됩니다. 첫 X개의 레코드는 첫 번째 태스크로, 다음 X개는 다음 태스크로, 이런 식으로 진행됩니다.

각 태스크는 별도로 처리되므로, 그 태스크는 최소한 하나의 레코드가 있는 각 파티션에 대해 하나의 파일을 생성합니다. 따라서 파티션 A에 속하는 10개의 레코드가 10개의 태스크에 분산되어 있다면, 각각 하나의 레코드가 있는 해당 파티션에 10개의 파일이 생기게 되며, 이는 이상적이지 않습니다.

해당 파티션의 모든 레코드가 동일한 태스크에 할당되어 같은 파일에 쓰일 수 있다면 더 좋을 것입니다. 이것이 쓰기 분배가 중요한 이유입니다. 즉, 데이터가 태스크 간에 어떻게 분배되는지입니다. 세 가지 옵션이 있습니다:

**none**  
특별한 분배가 없습니다. 이는 쓰기 시간 동안 가장 빠르며 미리 정렬된 데이터에 이상적입니다.

**hash**  
데이터는 파티션 키로 해시 분배됩니다.

**range**  
데이터는 파티션 키 또는 정렬 순서로 범위 분배됩니다.

해시 분배에서는 각 레코드의 값이 해시 함수를 통과하고 결과에 따라 함께 그룹화됩니다. 해시 함수에 따라 여러 값이 동일한 그룹에 속할 수 있습니다. 예를 들어, 데이터에 1, 2, 3, 4, 5, 6 값이 있다면, 1과 4는 태스크 A에, 2와 5는 태스크 B에, 3과 6은 태스크 C에 있는 해시 분배를 얻을 수 있습니다. 모든 파티션에 필요한 최소 파일 수를 여전히 작성하지만, 순차적 쓰기는 덜 관여됩니다.

범위 분배에서는 데이터가 정렬되고 분배되어, 태스크 A에 값 1과 2, 태스크 B에 3과 4, 태스크 C에 5와 6이 있을 가능성이 높습니다. 이 정렬은 파티션 값 또는 테이블에 SortOrder가 있는 경우 SortOrder에 의해 수행됩니다. 즉, SortOrder가 지정되면 데이터는 파티션 값뿐만 아니라 SortOrder 필드 값에 따라 태스크로 그룹화됩니다. 이는 특정 필드에서 클러스터링의 혜택을 받을 수 있는 데이터에 이상적입니다. 그러나 분배를 위해 데이터를 순차적으로 정렬하는 것은 데이터를 해시 함수에 넣고 출력을 기반으로 분배하는 것보다 더 많은 오버헤드가 있습니다.

삭제, 업데이트 및 병합에 대한 동작을 지정하는 쓰기 분배 속성도 있습니다:

```sql
ALTER TABLE catalog.MyTable SET TBLPROPERTIES (
 'write.distribution-mode'='hash',
 'write.delete.distribution-mode'='none',
 'write.update.distribution-mode'='range',
 'write.merge.distribution-mode'='hash',
);
```

정기적으로 많은 행을 업데이트하지만 행을 거의 삭제하지 않는 상황에서는 쿼리 패턴에 따라 다른 분배 모드가 더 유리할 수 있으므로 다른 분배 모드를 원할 수 있습니다.

## 객체 스토리지 고려사항

객체 스토리지는 데이터 저장에 대한 독특한 접근 방식입니다. 전통적인 파일 시스템처럼 파일을 깔끔한 폴더 구조로 유지하는 대신, 객체 스토리지는 모든 것을 버킷이라고 불리는 곳에 던져 넣습니다. 각 파일은 객체가 되고 여기에 메타데이터가 태그로 첨부됩니다. 이 메타데이터는 파일에 대한 모든 종류의 정보를 알려주며, 기본 파일이 지역 액세스나 동시성을 위해 복제될 수 있는 동안 모든 사용자가 단순한 "객체"로 상호 작용하며 객체 스토리지를 사용할 때 개선된 동시성과 복원력을 가능하게 합니다.

객체 스토리지에서 파일을 가져오려고 할 때, 폴더를 클릭해서 이동하지 않습니다. 대신 API를 사용합니다. 웹사이트와 상호 작용하기 위해 GET 또는 PUT 요청을 사용하는 것처럼, 여기서도 데이터에 액세스하기 위해 동일한 작업을 수행합니다. 예를 들어, 파일을 요청하기 위해 GET 요청을 사용하면 시스템이 파일을 찾기 위해 메타데이터를 확인하고, 짜잔! 데이터를 얻게 됩니다.

이 API 우선 접근 방식은 시스템이 데이터를 처리하는 데 도움이 됩니다. 예를 들어 다른 위치에 사본을 만들거나 동시에 많은 요청을 처리하는 것과 같은 작업이 가능합니다. 대부분의 클라우드 공급업체가 제공하는 객체 스토리지는 데이터 레이크 및 데이터 레이크하우스에 이상적이지만, 한 가지 잠재적 병목 현상이 있습니다.

아키텍처와 객체 저장소가 병렬 처리를 처리하는 방식 때문에, 종종 동일한 "접두사" 아래의 파일에 대한 요청에 제한이 있습니다. 따라서 /prefix1/fileA.txt와 /prefix1/fileB.txt에 액세스하려는 경우, 이들이 다른 파일이더라도 둘 다 접근하는 것은 prefix1에 대한 제한에 포함됩니다. 이는 많은 파일이 있는 파티션에서 문제가 되며, 쿼리가 이러한 파티션에 많은 요청을 초래하여 쿼리 속도를 늦추는 스로틀링에 부딪힐 수 있습니다.

파티션의 파일 수를 제한하기 위해 압축을 실행하는 것이 도움이 될 수 있지만, 아파치 아이스버그는 파일이 물리적으로 어떻게 배치되는지에 의존하지 않기 때문에 이 시나리오에 특히 적합합니다. 즉, 동일한 파티션의 파일을 여러 접두사에 쓸 수 있습니다.

다음과 같이 테이블 속성에서 이를 활성화할 수 있습니다:

```sql
ALTER TABLE catalog.MyTable SET TBLPROPERTIES (
 'write.object-storage.enabled'= true
);
```

이렇게 하면 같은 파티션의 파일이 잠재적 스로틀링을 피하기 위해 해시를 포함하여 여러 접두사에 분산됩니다.

그래서 다음과 같은 구조 대신:

```
s3://bucket/database/table/field=value1/datafile1.parquet
s3://bucket/database/table/field=value1/datafile2.parquet
s3://bucket/database/table/field=value1/datafile3.parquet
```

다음과 같은 구조를 얻게 됩니다:

```
s3://bucket/4809098/database/table/field=value1/datafile1.parquet
s3://bucket/5840329/database/table/field=value1/datafile2.parquet
s3://bucket/2342344/database/table/field=value1/datafile3.parquet
```

파일 경로에 해시가 있으면 동일한 파티션의 각 파일은 이제 다른 접두사 아래에 있는 것처럼 취급되어 스로틀링을 피할 수 있습니다.

## 데이터파일 블룸 필터

블룸 필터는 값이 데이터셋에 존재할 가능성이 있는지 알아내는 방법입니다. 비트(이진 코드의 0과 1) 라인업을 상상해보세요. 모두 사용자가 결정한 길이로 설정되어 있습니다. 이제 데이터셋에 데이터를 추가할 때, 각 값에 해시 함수라는 프로세스를 실행합니다. 이 함수는 비트 라인업의 위치를 출력하고, 그 비트를 0에서 1로 바꿉니다. 이 플립된 비트는 "이 위치에 해시되는 값이 데이터셋에 있을 수 있다"는 플래그와 같습니다.

예를 들어, 10개의 비트가 있는 블룸 필터에 1,000개의 레코드를 공급했다고 가정해 보겠습니다. 완료되면 블룸 필터는 다음과 같을 수 있습니다: [0,1,1,0,0,1,1,1,1,0]

이제 특정 값 X를 찾고 싶다고 가정해 보겠습니다. X를 동일한 해시 함수에 넣으면 비트 라인업의 3번 위치를 가리킵니다. 블룸 필터에 따르면 세 번째 위치에 1이 있습니다. 이는 이전에 이 위치에 해시된 값이 있기 때문에 값 X가 데이터셋에 있을 수 있다는 의미입니다. 그래서 데이터셋을 확인하여 X가 실제로 있는지 확인합니다.

이제 다른 값 Y를 찾아보겠습니다. Y를 해시 함수에 실행하면 비트 라인업의 네 번째 위치를 가리킵니다. 하지만 블룸 필터에는 그 위치에 0이 있습니다. 이는 이 위치에 해시된 값이 없다는 의미이므로 Y가 데이터셋에 확실히 없다고 자신 있게 말할 수 있으며, 데이터를 뒤지지 않고 시간을 절약할 수 있습니다.

블룸 필터는 불필요한 데이터 스캔을 피하는 데 유용합니다. 더 정확하게 만들려면 더 많은 해시 함수와 비트를 추가할 수 있습니다. 하지만 추가할수록 블룸 필터가 커지고 더 많은 공간이 필요하다는 점을 기억하세요. 대부분의 경우와 마찬가지로, 이는 균형을 맞추는 일입니다. 모든 것은 트레이드오프입니다.

테이블 속성을 통해 파켓 파일(ORC 파일에도 가능)의 특정 열에 대한 블룸 필터 작성을 활성화할 수 있습니다:

```sql
ALTER TABLE catalog.MyTable SET TBLPROPERTIES (
 'write.parquet.bloom-filter-enabled.column.col1'= true,
 'write.parquet.bloom-filter-max-bytes'= 1048576
);
```

그러면 데이터를 쿼리하는 엔진은 이러한 블룸 필터를 활용하여 필요한 데이터가 없다는 것이 분명한 데이터파일을 건너뛰어 데이터파일 읽기를 더 빠르게 할 수 있습니다.

## 결론

이 장에서는 아이스버그 테이블의 성능을 최적화하기 위한 다양한 전략을 살펴보았습니다. 압축, 정렬, z-ordering, copy-on-write 대 merge-on-read 메커니즘, 숨겨진 파티셔닝과 같은 중요한 테이블 성능 최적화 방법을 살펴보았습니다. 이러한 각 구성 요소는 쿼리 효율성 향상, 읽기 및 쓰기 시간 단축, 자원의 최적 활용을 보장하는 데 중요한 역할을 합니다. 이러한 전략을 효과적으로 이해하고 구현하면 아파치 아이스버그 테이블의 관리 및 운영을 크게 개선할 수 있습니다.

5장에서는 아이스버그 카탈로그 개념을 탐구하여 아이스버그 테이블이 도구 간에 이식 가능하고 검색 가능하도록 보장하는 방법을 살펴보겠습니다.
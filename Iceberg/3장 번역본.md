
## Merge Query

다음 쓰기 작업으로는 UPSERT/MERGE INTO를 수행하겠습니다. 이러한 쿼리는 보통 특정 값이 테이블에 존재할 경우 기존 행을 업데이트하고, 존재하지 않는 경우 새로운 행을 삽입할 때 실행됩니다.

예를 들어, orders_staging이라는 스테이지 테이블이 있고, 이 테이블에는 두 개의 레코드가 있다고 가정해 보겠습니다. 하나는 기존 order_id(order_id=123)에 대한 업데이트이고 다른 하나는 완전히 새로운 주문입니다. 각 주문에 대해 최신 세부 정보를 유지하기 위해 대상 테이블(orders)에서 order_id가 이미 존재하는 경우 order_amount를 업데이트하고, 그렇지 않으면 새 레코드를 삽입하려고 합니다. 다음은 쿼리입니다:

```sql
# Spark SQL
MERGE INTO orders o
USING (SELECT * FROM orders_staging) s
ON o.order_id = s.order_id
WHEN MATCHED THEN UPDATE SET order_amount = s.order_amount
WHEN NOT MATCHED THEN INSERT *;

# Dremio
MERGE INTO orders o
USING (SELECT * FROM orders_staging) s
ON o.order_id = s.order_id
WHEN MATCHED THEN UPDATE SET order_amount = s.order_amount
WHEN NOT MATCHED THEN INSERT (order_id, customer_id, order_amount, order_ts)
VALUES (s.order_id, s.customer_id, s.order_amount, s.order_ts)
```

이 쿼리는 다음 데이터셋을 병합합니다:

orders:

|order_id|customer_id|order_amount|order_ts|
|---|---|---|---|
|123|456|36.17|2023-03-07 08:10:23|

orders_staging:

|order_id|customer_id|order_amount|order_ts|
|---|---|---|---|
|123|456|50.5|2023-03-07 08:10:23|
|124|326|60|2023-01-27 10:05:03|

### 쿼리를 엔진으로 전송

먼저, 쿼리는 쿼리 엔진에 의해 구문 분석됩니다. 이 경우 두 개의 테이블(스테이지와 대상)이 관련되어 있으므로, 엔진은 쿼리 계획을 시작하기 위해 두 테이블의 데이터가 필요합니다.

### 카탈로그 확인

이전 INSERT 작업에서 논의한 것과 유사하게, 쿼리 엔진은 먼저 카탈로그에 현재 메타데이터 파일 위치를 확인하고 이를 읽습니다. 이 실습에서 사용된 카탈로그는 Hadoop이므로, 엔진은 /orders/metadata/version-hint.txt 파일을 읽고 그 내용을 가져옵니다. 이 값은 정수 2입니다. 이 정보를 얻고 카탈로그 로직을 사용하여 엔진은 현재 메타데이터 파일 위치가 /orders/metadata/v2.metadata.json임을 알게 됩니다. 이는 이전 INSERT 작업에서 생성한 파일이므로 엔진은 이 파일을 읽습니다. 그런 다음 쓰기 작업이 이를 준수할 수 있도록 테이블의 현재 스키마를 확인합니다. 마지막으로, 엔진은 파티셔닝 전략에 따라 데이터 파일이 어떻게 구성되는지 알아보고 새로운 데이터 파일 작성을 시작합니다.

### 데이터 파일 및 메타데이터 파일 작성

먼저, 쿼리 엔진은 order_id 필드를 기반으로 각 테이블의 모든 레코드를 통과하면서 일치하는 레코드를 찾기 위해 orders_staging과 orders 테이블 모두에서 데이터를 읽고 메모리에 로드합니다. 나중에 READ 프로세스에 대해 자세히 살펴보겠습니다.

여기서 중요한 점은 엔진이 일치 항목을 결정할 때 메모리에서 추적되는 내용이 Iceberg 테이블 속성에 의해 정의된 두 가지 전략에 따라 달라진다는 것입니다: copy-on-write(COW)와 merge-on-read(MOR).

이 두 전략에 대해서는 4장에서 더 자세히 다루겠지만, 간단히 말해서 COW 전략에서는 Iceberg 테이블이 업데이트될 때마다 관련 레코드가 있는 데이터 파일이 새 데이터 파일로 다시 작성됩니다. 그러나 MOR에서는 데이터 파일이 다시 작성되지 않고, 대신 변경 사항을 추적하기 위해 새 삭제 파일이 생성됩니다.

여기서는 COW 전략을 사용하겠습니다. 따라서 orders 테이블에서 order_id = 123인 레코드가 포함된 0_0_0.parquet 데이터 파일이 메모리에 읽힙니다. 그런 다음 이 order_id에 대한 order_amount 필드가 order_staging 테이블의 새로운 order_amount로 이 데이터의 인메모리 복사본에서 업데이트됩니다. 마지막으로, 이러한 수정된 세부 정보가 새 Parquet 데이터 파일에 기록됩니다:

```
s3://datalake/db1/orders/data/order_ts_hour=2023-03-07-08/0_0_1.parquet
```

이 특정 예제에서는 orders 테이블에 레코드가 하나만 있었습니다. 그러나 이 테이블에 쿼리에 지정된 조건과 일치하지 않는 다른 레코드가 있었더라도, 엔진은 여전히 이러한 모든 레코드의 복사본을 만들고 일치하는 행만 업데이트하며 일치하지 않는 행은 독립적인 파일에 작성됩니다. 이는 COW 쓰기 전략 때문입니다. 4장에서 이러한 쓰기 전략에 대해 더 자세히 알아볼 것입니다.

이제 조건과 일치하지 않는 order_staging 테이블의 레코드는 일반 INSERT로 처리되어 hour(order_ts) 값이 이 레코드에 대해 다르므로 다른 파티션에 새 데이터 파일로 작성됩니다:

```
s3://datalake/db1/orders/data/order_ts_hour=2023-01-27-10/0_0_0.parquet
```

데이터 파일을 작성한 후, 엔진은 이 두 데이터 파일의 파일 경로에 대한 참조를 보유하는 새 매니페스트 파일을 생성합니다. 또한 이러한 데이터 파일에 대한 다양한 통계(열의 하한 및 상한, 값 개수 등)가 매니페스트 파일에 포함됩니다:

```
s3://datalake/db1/orders/metadata/faf71ac0-3aee-4910-9080-c2e688148066.avro
```

결과 매니페스트 파일이 어떻게 보일 수 있는지 예제는 책의 GitHub 리포지토리에서 볼 수 있습니다.

그런 다음 엔진은 이전 단계에서 생성된 매니페스트 파일을 가리키는 새 매니페스트 목록을 생성합니다. 또한 기존 매니페스트 파일을 추적하고 매니페스트 목록을 데이터 레이크에 작성합니다:

```
s3://datalake/db1/orders/metadata/snap-5139476312242609518-1-e22ff753-2738-4d7da810-d65dcc1abe63.avro
```

매니페스트 목록을 검사할 때(책의 GitHub 리포지토리 참조), 파티션 통계 및 추가 및 삭제된 파일 수와 같은 항목도 볼 수 있습니다.

그 후, 엔진은 이전에 현재였던 메타데이터 파일인 v2.metadata.json과 그 일부로 포함된 스냅샷 s0 및 s1을 기반으로 새 스냅샷 s2와 함께 새 메타데이터 파일 v3.metadata.json을 생성합니다(책의 GitHub 리포지토리에서 이것이 어떻게 보일지 예제를 볼 수 있습니다):

```
s3://datalake/db1/orders/metadata/v3.metadata.json
```

### 변경 사항을 커밋하기 위해 카탈로그 파일 업데이트

마지막으로, 엔진은 이 시점에서 쓰기 충돌이 없는지 확인한 다음 카탈로그를 최신 메타데이터 파일인 v3.metadata.json의 값으로 업데이트합니다. 시각적으로, UPSERT 작업의 이 단계에서 Iceberg 컴포넌트는 그림 3-5와 같이 보일 것입니다.

## Apache Iceberg에서의 읽기 쿼리

Apache Iceberg 테이블에서 데이터를 읽는 것은 잘 정의된 일련의 작업을 따르며, 쿼리가 실행 가능한 인사이트로 원활하게 변환될 수 있게 합니다. 읽기 쿼리가 시작되면 먼저 쿼리 엔진으로 전송됩니다. 엔진은 카탈로그를 활용하여 최신 메타데이터 파일 위치를 검색하며, 이 파일에는 테이블의 스키마와 결국 실제 데이터 파일로 이어지는 매니페스트 목록과 같은 중요한 정보가 포함되어 있습니다. 이 과정에서 열에 대한 통계 정보가 사용되어 읽히는 파일 수를 제한하므로 쿼리 성능이 향상됩니다.

## SELECT 쿼리

이 섹션에서는 READ 쿼리가 실행될 때 Apache Iceberg의 다양한 구성 요소들이 어떻게 함께 작동하는지 알아보겠습니다. 다음은 실행할 쿼리입니다:

```sql
# Spark SQL/Dremio Sonar
SELECT *
FROM orders
WHERE order_ts BETWEEN '2023-01-01' AND '2023-01-31'
```

### 쿼리를 엔진으로 전송

이 단계에서 엔진은 메타데이터 파일을 기반으로 쿼리 계획을 시작합니다.

### 카탈로그 확인

쿼리 엔진은 카탈로그에 orders 테이블의 현재 메타데이터 파일 경로를 요청한 다음 이를 읽습니다. 이전 두 섹션에서 논의한 바와 같이, 여기서 Hadoop 카탈로그를 사용하고 있으므로 엔진은 /orders/metadata/version-hint.txt 파일을 읽습니다. 이 파일의 내용은 단일 정수 3입니다. 이 정보와 카탈로그 구현 로직을 기반으로 엔진은 현재 메타데이터 파일 위치가 /orders/metadata/v3.metadata.json임을 알게 됩니다. 이는 이전 MERGE INTO 작업이 생성한 파일입니다.

### 메타데이터 파일에서 정보 가져오기

그런 다음 엔진은 메타데이터 파일 v3.metadata.json을 열고 읽어 몇 가지 정보를 가져옵니다. 먼저 데이터를 읽기 위한 내부 메모리 구조를 준비하기 위해 테이블의 스키마를 결정합니다. metadata.json 파일의 데이터 예제는 책의 GitHub 리포지토리에서 볼 수 있습니다. 그런 다음 데이터가 어떻게 구성되어 있는지 이해하기 위해 테이블의 파티셔닝 스키마에 대해 알아봅니다. 쿼리 엔진은 나중에 이를 활용하여 관련 없는 데이터 파일을 건너뛸 수 있습니다.

엔진이 메타데이터 파일에서 검색하는 가장 중요한 정보 중 하나는 current-snapshot-id입니다. 이는 테이블의 현재 상태를 나타냅니다. current-snapshot-id를 기반으로 엔진은 더 나아가 관련 파일을 스캔하기 위해 snapshots 배열에서 매니페스트 목록 파일 경로를 찾습니다.

### 매니페스트 목록에서 정보 가져오기

메타데이터 파일에서 매니페스트 목록 파일 경로 위치를 얻은 후, 쿼리 엔진은 snap-5139476312242609518-1-e22753-2738-4d7d-a810-d65dcc1abe63.avro 파일을 읽어 더 자세한 내용을 확인합니다(예제는 책의 GitHub 리포지토리 참조). 이 파일에서 엔진이 얻는 가장 중요한 정보는 해당 매니페스트 목록 내의 각 스냅샷에 대한 매니페스트 파일 경로 위치입니다. 엔진은 특정 쿼리에 대한 관련 데이터 파일을 가져오기 위해 이 정보가 필요합니다.

매니페스트 목록에는 또한 partition-spec-id와 같은 파티션에 대한 중요한 정보가 포함되어 있습니다. 이는 특정 스냅샷을 작성하는 데 사용된 파티션 스키마에 대해 엔진에 알려줍니다. 현재 이 필드의 값은 0이며(책의 GitHub 리포지토리 참조), 이는 테이블에 정의된 유일한 파티션임을 의미합니다.

매니페스트에 대한 파티션 열의 하한 및 상한과 같은 다른 파티션별 통계도 있습니다. 이 정보는 엔진이 더 나은 파일 가지치기를 위해 어떤 매니페스트 파일을 건너뛸지 결정할 때 유용합니다. 각 스냅샷에 대해 추가/삭제된 총 데이터 파일 수와 추가/삭제된 행 수와 같은 다른 세부 정보도 이 파일에서 찾을 수 있습니다.

### 매니페스트 파일에서 정보 가져오기

그런 다음 엔진은 가지치기되지 않은(즉, 쿼리와 관련된) 매니페스트 파일 faf71ac0-3aee-4910-9080-c2e688148066.avro를 엽니다. 세부 정보를 얻기 위해 파일을 읽습니다(예제는 책의 GitHub 리포지토리 참조). 먼저, 쿼리 엔진은 이 매니페스트 파일이 추적하는 데이터 파일을 나타내는 각 항목을 스캔합니다. 이러한 각 데이터 파일이 속한 파티션 값을 쿼리 필터에 사용된 값과 비교합니다.

쿼리에서 '2023-01-01'과 '2023-01-31' 사이의 모든 주문 세부 정보를 가져오도록 요청했습니다. 따라서 엔진은 파티션 값인 2023-03-07-08을 무시합니다. 필터 값이 파티션 값과 일치하면 엔진은 이 파티션의 모든 레코드를 확인합니다.

파티션 값을 기반으로 엔진은 해당 데이터 파일인 0_0_0.parquet을 찾습니다. 엔진은 또한 관련 없는 파일을 건너뛰기 위해 각 열의 하한 및 상한 및 null 값 개수와 같은 다른 통계 정보를 수집합니다.

Apache Iceberg에서 기본적으로 사용할 수 있는 파티셔닝 및 메트릭 기반 필터링(열의 상한/하한)과 같은 데이터 및 파일 최적화 기술은 이 예제에서 볼 수 있듯이 전체 테이블 스캔을 피할 수 있게 하여 상당한 성능 보장을 촉진합니다. 마지막으로, 레코드가 사용자에게 반환됩니다:

```
order_id customer_id order_amount order_ts
1 125 321 20.50 2023-01-27 10:30:05 +00:00
```

시각적으로 이 전체 READ 프로세스는 그림 3-6과 같습니다.

그림 3-6을 참조하면 다음 사항에 유의하세요:

1. 쿼리 엔진은 현재 메타데이터 파일(v3.metadata.json)을 가져오기 위해 카탈로그와 상호 작용합니다.
2. 그런 다음 현재 스냅샷 ID(이 경우 S2)와 해당 스냅샷에 대한 매니페스트 목록 위치를 가져옵니다.
3. 그런 다음 매니페스트 목록에서 매니페스트 파일 경로를 검색합니다.
4. 엔진은 매니페스트 파일에서 파티션 필터(2023-03-07-08)를 기반으로 데이터 파일 경로를 결정합니다.
5. 필요한 데이터 파일에서 일치하는 데이터가 사용자에게 반환됩니다.


# 시간 여행 쿼리

데이터베이스와 데이터 웨어하우스 세계에서 중요한 기능 중 하나는 테이블의 특정 시점 상태로 돌아가 과거 데이터(변경되거나 삭제된 데이터)를 조회하는 능력입니다. Apache Iceberg는 데이터 레이크하우스 아키텍처에 이와 유사한 시간 여행 기능을 제공합니다. 이는 이전 분기의 조직 데이터 분석, 실수로 삭제된 행 복원, 분석 결과 재현과 같은 시나리오에 특히 유용할 수 있습니다. Apache Iceberg는 타임스탬프와 스냅샷 ID를 사용하는 두 가지 방법으로 시간 여행 쿼리를 실행할 수 있습니다.

이 섹션에서는 Apache Iceberg 테이블에서 시간 여행 쿼리를 실행하는 방법을 배우게 됩니다. 이 시연을 위해, MERGE INTO 쿼리를 실행하기 전의 상태(즉, INSERT 문만 실행했을 때의 상태)로 돌아가야 한다고 가정해 보겠습니다. 그러한 가정이 주어졌을 때, 먼저 Iceberg 테이블의 히스토리를 이해해야 합니다. Apache Iceberg의 가장 좋은 점 중 하나는 메타데이터 테이블이라 불리는 시스템 테이블을 통해 다양한 테이블별 메타데이터 정보를 분석할 수 있다는 것입니다. 메타데이터 테이블에 대해서는 10장에서 자세히 배우게 됩니다. 주문 테이블의 히스토리를 분석하기 위해 히스토리 메타데이터 테이블을 쿼리해 보겠습니다(이 섹션의 메타데이터 예제는 책의 GitHub 리포지토리에서 확인할 수 있습니다):

```sql
# Spark SQL
SELECT * FROM catalog.db.orders.history;
# Dremio
SELECT * FROM TABLE (table_history('orders'))
```

이는 이 테이블에서 발생한 모든 트랜잭션 목록을 제공합니다:

```
made_current_at         snapshot_id                parent_id                  is_current_ancestor
2023-03-06 21:28:35.360 7327164675870333694       null                       true
2023-03-07 20:45:08.914 8333017788700497002       7327164675870333694       true
2023-03-09 19:58:40.448 5139476312242609518       8333017788700497002       true
```

히스토리 메타데이터 테이블을 요약하면:

- 첫 번째 스냅샷(ID: 7327164675870333694)은 CREATE 문을 실행한 후 생성되었습니다.
- 두 번째 스냅샷(8333017788700497002)은 INSERT 문을 사용하여 새 레코드를 삽입한 후 생성되었습니다.
- 마지막으로, MERGE INTO 쿼리가 세 번째 스냅샷(5139476312242609518)을 생성했습니다.

최종 트랜잭션(즉, MERGE) 이전 상태로 시간 여행해야 하므로, 타임스탬프나 스냅샷 ID는 두 번째 것을 대상으로 합니다. 다음은 실행할 쿼리입니다:

```sql
# Spark SQL
SELECT * FROM orders
TIMESTAMP AS OF '2023-03-07 20:45:08.914'
# Dremio Sonar
SELECT * FROM orders
AT TIMESTAMP '2023-03-07 20:45:08.914'
```

정확한 타임스탬프 값을 제공하지 않으면, Iceberg는 지정된 값보다 오래된 스냅샷을 찾아 결과를 반환합니다. 더 오래된 스냅샷이 존재하지 않으면 Iceberg는 다음과 같은 예외를 발생시킵니다:

```
IllegalArgumentException: Cannot find a snapshot older than 2023-03-06T21:28:35+00:00.
```

스냅샷 ID를 사용하여 시간 여행하려면 쿼리는 다음과 같습니다:

```sql
# Spark SQL
SELECT *
FROM orders
VERSION AS OF 8333017788700497002
# Dremio
SELECT *
FROM orders
AT SNAPSHOT 8333017788700497002
```

이제 시간 여행 쿼리가 실행될 때 Iceberg 컴포넌트에서 어떤 일이 발생하는지, 그리고 관련 데이터 파일이 사용자에게 어떻게 반환되는지 빠르게 살펴보겠습니다.

## 쿼리를 엔진에 보내기

다른 SELECT 문과 마찬가지로, 쿼리는 먼저 엔진에 전송되어 파싱됩니다. 엔진은 테이블 메타데이터를 활용하여 쿼리 계획을 시작합니다.

## 카탈로그 확인

이 단계에서 쿼리 엔진은 카탈로그에 현재 메타데이터 파일 위치를 알기 위해 요청하고 이를 읽습니다. 이 연습에서는 Hadoop 카탈로그를 활용했으므로, 엔진은 /orders/metadata/version-hint.txt 파일의 내용을 읽을 것이며, 이는 정수 3입니다. 이 정보와 카탈로그 구현 로직에 따라 엔진은 현재 메타데이터 파일 위치가 /orders/metadata/v3.metadata.json임을 확인합니다. 이것은 이전 MERGE INTO 작업이 생성한 파일이므로 엔진이 이 파일을 읽게 됩니다.

## 메타데이터 파일에서 정보 가져오기

다음으로, 엔진은 테이블 정보를 얻기 위해 메타데이터 파일을 읽습니다. 현재 메타데이터 파일은 메타데이터 유지 관리 전략의 일부로 의도적으로 만료되지 않는 한 Iceberg 테이블에 대해 생성된 모든 스냅샷을 추적합니다(이에 대해서는 4장에서 자세히 다룹니다). 사용 가능한 스냅샷 목록에서 엔진은 시간 여행 쿼리에 지정된 타임스탬프 값이나 스냅샷 ID에 기반하여 특정 스냅샷을 결정합니다.

엔진은 또한 테이블의 스키마와 파티셔닝 체계에 대해 배워 나중에 파일 정리에 활용합니다. 마지막으로, 해당 스냅샷에 대한 매니페스트 리스트 경로 위치를 가져옵니다:

```
s3://datalake/db1/orders/metadata/snap-8333017788700497002-1-4010cc03-5585-458c-9fdc-188de318c3e6.avro
```

## 매니페스트 리스트에서 정보 가져오기

매니페스트 리스트 경로를 기반으로 엔진은 스냅샷에 대한 데이터가 포함된 지정된 .avro 파일을 열고 읽습니다. 엔진은 매니페스트 리스트에서 몇 가지 중요한 정보를 도출합니다:

- 실제 데이터 파일에 대한 참조를 보유하는 매니페스트 파일 경로 위치:
    
    ```
    s3://datalake/db1/orders/metadata/62acb3d7-e992-4cbc-8e41-58809fcacb3e.avro
    ```
    
- 추가/삭제된 데이터 파일 수와 파티션에 대한 통계 정보와 같은 정보

## 매니페스트 파일에서 정보 가져오기

마지막으로, 엔진은 쿼리와 일치하는 모든 매니페스트 파일을 읽고 세부 정보를 가져옵니다. 매니페스트 파일에서 가장 중요한 정보는 쿼리에 대한 레코드가 있는 파일 경로를 포함하는 데이터 파일 경로입니다. 엔진은 매니페스트에 있는 각 데이터 파일을 읽어야 하는지 여부를 결정합니다. 데이터 파일 경로 위치 외에도 엔진은 이전 섹션에서 논의된 컬럼에 대한 통계 정보도 수집합니다.

결국, 엔진은 데이터 파일 0_0_0.parquet를 읽고, 다음 출력이 사용자에게 반환됩니다:

```
order_id customer_id order_amount order_ts
123      456         36.17        2023-03-07 08:10:23 +00:00
```

이것은 MERGE INTO 쿼리를 실행하기 전에 테이블에 삽입한 레코드입니다. 그림 3-7은 이 프로세스의 시각적 요약을 제공합니다.

그림 3-7을 참조하면 다음과 같습니다:

1. 쿼리 엔진은 카탈로그와 상호 작용하여 현재 메타데이터 파일(v3.metadata.json)을 가져옵니다.
2. 그런 다음 시간 여행 쿼리에서 제공된 타임스탬프나 버전 ID를 기반으로 스냅샷(이 경우 S1)을 선택하고 해당 스냅샷에 대한 매니페스트 리스트 위치를 가져옵니다.
3. 매니페스트 파일 경로는 매니페스트 리스트에서 검색됩니다.
4. 엔진은 매니페스트 파일에서 파티션 필터(2023-03-07-08)를 기반으로 데이터 파일 경로를 결정합니다.
5. 필요한 데이터 파일에서 일치하는 데이터가 사용자에게 반환됩니다.

# 결론

이 장에서는 테이블 생성과 레코드 삽입 및 업데이트와 같은 다양한 읽기 및 쓰기 쿼리의 내부 작동 방식을 논의하여 컴퓨트 엔진이 Apache Iceberg의 다양한 아키텍처 구성 요소를 어떻게 활용하는지 이해했습니다.

4장에서는 테이블에서 데이터를 읽고 쓸 때 높은 성능을 보장하기 위해 Apache Iceberg에서 즉시 사용 가능한 최적화 기술에 대해 다룰 것입니다.
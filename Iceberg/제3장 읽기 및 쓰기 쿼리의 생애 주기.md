

Apache Iceberg 테이블 포맷은 고성능 쿼리를 제공하여 데이터 레이크에서 직접 OLAP 워크로드를 실행할 수 있게 해준다. 이러한 고성능 쿼리를 실행 가능하게 하는 것은 Iceberg 테이블 포맷이 Catalog layer / Metadata layer / Data layer 라는 컴포넌트로 아키텍쳐가 이루어져있기 때문이다.

![[IMG-20250401-제3장 읽기 및 쓰기 쿼리의 생애 주기-Pasted image 20250401223147.png]]

#### Catalog layer
- 카탈로그는 각 테이블의 `Current metadata pointer`, 즉 최신 메타데이터 파일이 어떤 파일인지에 대한 정보를 가지고 있다.
- 읽기 쿼리를 수행하던, 쓰기 쿼리를 수행하던 쿼리 엔진이 가장 먼저 상호작용하는 컴포넌트.
- 읽기 쿼리의 경우, 엔진은 테이블의 현재 상태를 알기 위해 카탈로그에 접근.
- 쓰기 쿼리의 경우, 엔진은 정의된 스키마를 준수하고 테이블 파티셔닝 방식을 알기 위해 카탈로그에 접근.

#### Metadata layer
- 메타데이터 파일 / 매니페스트 리스트 / 매니페스트 파일로 구성.
- 쿼리 엔진이 Iceberg 테이블에 무언가를 쓸 때마다, 새로운 메타데이터 파일이 [[atomic하게 생성]]되어 최신 버전의 메타데이터 파일로 정의 된다.
	- 테이블 커밋의 선형적 히스토리를 보장하며, 동시 쓰기(여러 엔진이 동시에 데이터를 쓰는 경우)와 같은 시나리오에서 도움이 된다.
	- 읽기 쿼리 엔진은 항상 테이블의 최신 버전을 볼 수 있다.
- 쿼리 엔진은 더 빠른 쿼리 성능을 위해 필요하지 않은 매니페스트 파일을 건너 뛰는데 도움이 되는 파티션 정보를 얻기 위해 매니페스트 리스트를 참조 한다.
- 매니페스트 파일은 특정 열의 바운더리, null 값의 수, 파티션별 데이터와 같은 정보를 가지고 있으며, 엔진은 해당 정보를 이용하여 파일 pruning에 사용한다.

#### Data layer
- 쿼리 엔진은 특정 쿼리에 필요한 데이터 파일을 효율적으로 읽기 위해 메타데이터 파일을 필터링한다.
- 쓰기 측면에서는 데이터 파일이 파일 저장소에 쓰여지고, 관련 메타데이터 파일이 그에 따라 생성되고 업데이트 된다.


## Apache Iceberg에서 쓰기 쿼리

![[IMG-20250401-제3장 읽기 및 쓰기 쿼리의 생애 주기-Pasted image 20250401233117.png]]

## Create the Table

기본 프로세스를 이해할 수 있도록 Iceberg 테이블을 만드는 것부터 시작한다.
아래 쿼리는 4개의 컬럼이 있는 `orders`라는 테이블을 생성한다. 이 테이블은 order_ts 컬럼의 시간 단위로 파티셔닝되어 있다. 
이때 Iceberg 테이블에서는 파티셔닝을 위해 명시적인 컬럼을 추가할 필요가 없다는 점에 주목하자.

![[IMG-20250401-제3장 읽기 및 쓰기 쿼리의 생애 주기-Pasted image 20250401233648.png]]

#### 테이블이 생성되는 과정

1. 쿼리는 구문 분석을 위해 쿼리 엔진으로 전송된다.
2. CREATE 문을 사용했기 때문에 엔진이 테이블을 생성하고 정의하기 시작한다.
3. 엔진은 데이터 레이크 파일시스템에 `v1.metadata.json` 이라는 메타데이터 파일을 생성하여 테이블에 관한 정보를 저장하기 시작한다.
   (메타데이터파일의 일반적인 경로 형태 :  `s3://path/to/warehouse/db1/table1/metadata/v1.metadata.json`)
   테이블 경로인 `/path/to/warehouse/db1/table1/` 를 기반으로 엔진은 메타데이터 파일을 작성한다.
4. 컬럼과 데이터 타입을 지정하여 `order` 테이블의 스키마를 정의하고 이를 메타데이터 파일에 저장한다.
5. 테이블의 고유 식별자(table-uuid)를 할당한다.
6. 쿼리가 성공적으로 실행되면 메타데이터 파일 `v1.metadata.json`을 데이터 레이크 파일 스토리지에 저장된다.

v1.metadata.json
```json
{
"table-uuid" : "072db680-d810-49ac-935c-56e901cad686",
"schema" : {
    "type" : "struct",
    "schema-id" : 0,
    "fields" : [ {
        "id" : 1,
        "name" : "order_id",
        "required" : false,
        "type" : "long"
    }, {
        "id" : 2,
        "name" : "customer_id",
        "required" : false,
        "type" : "long"
    }, {
        "id" : 3,
        "name" : "order_amount",
        "required" : false,
        "type" : "decimal(10, 2)"
    }, {
        "id" : 4,
        "name" : "order_ts",
        "required" : false,
        "type" : "timestamptz"
    } ]
},
"partition-spec" : [ {
    "name" : "order_ts_hour",
    "transform" : "hour",
    "source-id" : 4,
    "field-id" : 1000
    } ]
}
```

이것은 테이블을 만들었지만 레코드가 없는 빈 테이블인 현재 테이블의 상태이다. 테이블의 현재 상태를 나타내는 것을 Iceberg 용어로 `스냅샷(snapshot)`이라고 한다.

여기서 중요한 점은 데이터가 없는 빈 테이블이기 때문에 데이터 레이크에 데이터 파일이 없다는 것이다. 따라서 스냅샷(메타데이터파일)은 `매니페스트 리스트`를 가리키지 않으므로 `매니페스트 파일`도 없다.

7. 엔진은 카탈로그 파일인 `version-hint.txt`에 현재 가장 최신의 메타데이터인 `v1.metadata.json`파일을 가리키도록 `Current metadata pointer`를 업데이트 한다. 카탈로그 파일의 이름인 version-hint.txt는 선택한 카탈로그에 따라 달라진다. 
   여기서는 파일시스템 기반 Hadoop 카탈로그를 활용했다.
![[IMG-20250402-제3장 읽기 및 쓰기 쿼리의 생애 주기-Pasted image 20250402001844.png]]
`CREATE`를 실행한 후 Iceberg 컴포넌트의 계층 구조



## Insert the Query

이제 테이블에 데이터를 넣고 어떻게 동작하는지 이해해보자.

```sql
# SparkSQL Query Engine
INSERT INTO orders VALUES (
123,
456,
36.17,
'2023-03-07 08:10:23'
)
```

앞서 4개의 컬럼을 가지는 `oders`라는 테이블을 생성하였고, 이번에는 다음 쿼리를 통해 테이블에 데이터를 `insert` 할 것이다.

- order_id : 123
- customer_id : 456
- order_amount : 36.17
- oder_ts : 2023-03-07 08:10:23


#### 테이블에 데이터가 insert되는 과정

1. 쿼리는 구문 분석을 위해 쿼리 엔진으로 전송된다.
   `CREATE`와 달리 엔진은 쿼리 계획을 세우기 위해 테이블의 스키마와 같은 테이블에 관한 정보가 필요하다.
	> why? 테이블의 현재 스키마를 준수하고 파티셔닝 방식을 확인하여 적절한 형태로 데이터를 구성하기 위하여 테이블 정보가 필요.
2. 쿼리 엔진은 카탈로그에 요청하여 현재 메타데이터 파일의 위치를 얻는다.
   여기서는 Hadoop 카탈로그를 사용하므로, `/orders/metadata/version-hint.txt` 파일을 읽고 파일의 내용이 단일 정수 1임을 확인한다.
   이 정보와 카탈로그 구현 로직을 활용하여, 엔진은 현재 메타데이터 파일 위치가 `/orders/metadata/v1.metadata.json`(CREATE TABLE을 통해 생성한 파일) 임을 알게 된다.
   메타데이터 파일을 통해 스키마와 파티션닝 방식과 같은 테이블 정보를 알게 된다.
3. 엔진은 테이블에 정의된 시간별 파티셔닝 방식에 따라 데이터를 parquet 데이터 파일로 생성한다.(default : parquet)
   테이블에 데이터 정렬 순서가 정의되어 있으면, 레코드는 데이터 파일에 쓰여지기 전에 정렬된다.
   파일 시스템에서 데이터 파일 예시 : `s3://datalake/db1/orders/data/order_ts_hour=2023-03-07-08/0_0_0.parquet`
4. 데이터 파일을 작성한 후, 엔진은 매니페스트 파일을 생성한다.
   매니페스트 파일에는 엔진이 생성한 실제 데이터 파일의 경로에 대한 정보와 해당 파일이 가지고 있는 데이터의 컬럼 값 바운더리(상한값/하한값), null 값의 갯수와 같은 통계 정보가 있다.
   엔진은 매니패스트 파일 정보를 이용해서 최적의 쿼리 성능을 제공하기 위한 File Pruning에 이용한다.
   매니패스트 파일은 파일시스템에 `.avro` 파일로 작성된다.
   (`s3://datalake/db1/orders/metadata/62acb3d7-e992-4cbc-8e41-58809fcacb3e.avro`)
```json
{
"data_file" : {
	"file_path" : "s3://datalake/db1/orders/data/order_ts_hour=2023-03-07-08/0_0_0.parquet",
	"file_format" : "PARQUET",
	"block_size_in_bytes" : 67108864,
	"null_value_counts" : [],
	"lower_bounds" : {
		"array": [{
			"key": 1,
			"value": 123
		}],
	}
	"upper_bounds" : {
		"array": [{
			"key": 1,
			"value": 123
		}],
	},
}
}
```

5. 엔진은 매니페스트 파일을 추적하기 위한 매니페스트 리스트를 생성한다. 이 스냅샷과 연관된 기존 매니페스트 파일이 있다면, 그것들도 새로운 매니페스트 리스트에 추가될 것이다.
   엔진은 매니페스트 파일의 경로, 추가된거나 삭제된 데이터파일/행의 수, 파티션 컬럼의 바운더리(상한값/하한값)와 같은 통계 정보를 매니페스트 리스트에 작성한다.
   (`s3://datalake/db1/orders/metadata/snap-8333017788700497002-1-4010cc03-5585-458c-9fdc-188de318c3e6.avro`)
   > 이 정보는 읽기 쿼리 엔진이 불필요한 매니페스트 파일들을 읽지 않도록하여, 더 빠른 쿼리를 가능하게 한다.
```json
{
"manifest_path": "s3://datalake/db1/orders/metadata/62acb3d7-e992-4cbc-8e41-58809fcacb3e.avro",
"manifest_length": 6152,
"added_snapshot_id": 8333017788700497002,
"added_data_files_count": 1,
"added_rows_count": 1,
"deleted_rows_count": 0,
"partitions": {
	"array": [ {
		"contains_null": false,
		"lower_bound": {
			"bytes": "¹Ô\\u0006\\u0000"
		},
		"upper_bound": {
			"bytes": "¹Ô\\u0006\\u0000"
		}
	} ]
}
}
```
[[timestamp 값이 바이트 표현으로 변환된 과정과 이유]]

6. 엔진은 이전 메타데이터 파일인 `v1.metadata.json`을 참고하면서 이전 스냅샷 `s0`을 계속 추적하면서 새로운 스냅샷 `s1`을 포함한 새 메타데이터 파일 `v2.betadata.json`을 생성한다.
   새로운 메타데이터 파일에는 엔진이 생성한 매니페스트 리스트에 관한 정보가 포함되어 있으며, 매니페스트 리스트 파일 경로, 스냅샷ID, 작업 요약과 같은 세부 정보를 담고 있다.
   (`s3://datalake/db1/orders/metadata/v2.metadata.json`)

```json
"current-snapshot-id" : 8333017788700497002,
"refs" : {
	"main" : {
		"snapshot-id" : 8333017788700497002,
		"type" : "branch"
	}
},
"snapshots" : [ {
	"snapshot-id" : 8333017788700497002,
	"summary" : {
		"operation" : "append",
		"added-data-files" : "1",
		"added-records" : "1",
	},
	"manifest-list" : "s3://datalake/db1/orders/metadata/snap-8333017788700497002-1-4010cc03-5585-458c-9fdc-188de318c3e6.avro",
} ],
```
[[Apache Iceberg의 브랜치(branch) 타입에 대한 자세한 설명]]

```json
{
  "format-version" : 2,
  /* 기타 메타데이터 필드... */
  
  "current-snapshot-id" : 8333017788700497002,
  
  "refs" : {
    "main" : {
      "snapshot-id" : 8333017788700497002,
      "type" : "branch"
    },
    "development" : {
      "snapshot-id" : 9446128899811608113,  // 새로운 스냅샷 ID
      "type" : "branch"
    }
  },
  
  "snapshots" : [ 
    /* 기존 스냅샷 정보... */,
    {
      "snapshot-id" : 9446128899811608113,
      "parent-snapshot-id" : 8333017788700497002,  // 부모 스냅샷 참조
      "sequence-number" : 2,
      "timestamp-ms" : 1678265801234,
      "summary" : {
        "operation" : "append",
        "added-data-files" : "1",
        "added-records" : "1",
        "branch" : "development"  // 브랜치 정보 포함
      },
      "manifest-list" : "s3://datalake/db1/orders/metadata/snap-9446128899811608113-2-5ab7de04-6921-469c-a8d2-198de429d4f7.avro"
    }
  ]
}
```

7. 엔진은 `INSERT` 작업이 실행되는 동안 다른 스냅샷이 커밋되지 않았는지 확인하기 위해 카탈로그에 다시 접근한다. 이러한 검증을 통해 Iceberg는 여러 작업자가 동시에 데이터를 쓰는 시나리오에서 작업 간의 간섭이 없도록 보장한다.

![[IMG-20250402-제3장 읽기 및 쓰기 쿼리의 생애 주기-Pasted image 20250402012652.png]]
INSERT 실행 후 Iceberg의 컴포넌트 계층 구조